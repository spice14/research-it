{"id": "0", "text": "Abstract\n\nForgetting refers to the loss or deterioration of previously acquired knowledge. While existing surveys on forgetting have primarily focused on continual learning, forgetting is a prevalent phenomenon observed in various other research domains within deep learning. Forgetting manifests in research fields such as generative models due to generator shifts, and federated learning due to heterogeneous data distributions across clients. Addressing forgetting encompasses several challenges, including balancing the retention of old task knowledge with fast learning of new task, managing task interference with conflicting goals, and preventing privacy leakage, etc.\nMoreover, most existing ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "1", "text": "k interference with conflicting goals, and preventing privacy leakage, etc.\nMoreover, most existing surveys on continual learning implicitly assume that forgetting is always harmful. In contrast, our survey argues that forgetting is a double-edged sword and can be beneficial and desirable in certain cases, such as privacy-preserving scenarios. By exploring forgetting in a broader context, we present a more nuanced understanding of this phenomenon and highlight its potential advantages.\nThrough this comprehensive survey, we aspire to uncover potential solutions by drawing upon ideas and approaches from various fields that have dealt with forgetting. By examining forgetting beyond its conventi", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "2", "text": "hes from various fields that have dealt with forgetting. By examining forgetting beyond its conventional boundaries, we hope to encourage the development of novel strategies for mitigating, harnessing, or even embracing forgetting in real applications.\nA comprehensive list of papers about forgetting in various research fields is available at \nhttps://github.com/EnnengYang/Awesome-Forgetting-in-Deep-Learning\n.\n\n1 \nIntroduction\n\nForgetting \n[\n1\n]\n refers to the phenomenon where previously acquired information or knowledge in a machine learning system degrades over time. In the early days of neural networks, the focus was primarily on training models on static datasets. Forgetting was not a sig", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "3", "text": "al networks, the focus was primarily on training models on static datasets. Forgetting was not a significant concern since the models were trained and evaluated on fixed datasets.\nThe concept of catastrophic forgetting was first formally introduced by McCloskey and Cohen \n[\n1\n]\n. They demonstrated that neural networks when trained sequentially on different tasks, tend to forget previously learned tasks when new tasks are learned.\nLater, addressing the issue of forgetting was formalized as continual learning (CL). Nowadays, forgetting has garnered significant attention not only within the CL domain but also in the broader machine learning community, which has evolved into a fundamental proble", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "4", "text": "main but also in the broader machine learning community, which has evolved into a fundamental problem in the field of machine learning.\n\nExisting surveys on forgetting have primarily focused on CL \n[\n2\n, \n3\n, \n4\n, \n5\n, \n6\n, \n7\n, \n8\n, \n9\n]\n. However, these surveys tend to concentrate solely on the harmful effects of forgetting and lack a comprehensive discussion on the topic.\nIn contrast, we highlight the dual nature of forgetting as a double-edged sword, emphasizing both its benefits and harms. Additionally, our survey extends beyond the scope of CL and covers the forgetting issue in various other domains, including foundation models, domain adaptation, meta-learning, test-time adaptation, g", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "5", "text": "ther domains, including foundation models, domain adaptation, meta-learning, test-time adaptation, generative models, reinforcement learning and federated learning. By doing so, we offer a comprehensive examination of forgetting that encompasses a broader range of contexts and applications.\n\nTABLE I: \nHarmful Forgetting: Comparisons among different problem settings. \n\nProblem Setting\n\nGoal\n\nSource of Forgetting\n\nContinual Learning\n\nlearn non-stationary data distribution without forgetting previous knowledge\n\ndata-distribution shift during training\n\nFoundation Model\n\nunsupervised learning on large-scale unlabeled data\n\ndata-distribution shift in pre-training, fine-tuning\n\nDomain Adaptation\n\na", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "6", "text": "rge-scale unlabeled data\n\ndata-distribution shift in pre-training, fine-tuning\n\nDomain Adaptation\n\nadapt to target domain while maintaining performance on source domain\n\ntarget domain sequentially shift over time\n\nTest-time Adaptation\n\nmitigate the distribution gap between training and testing\n\nadaptation to the test data distribution during testing\n\nMeta Learning\n\nlearn adaptable knowledge to new tasks\n\nincrementally meta-learn new classes / task-distribution shift\n\nGenerative Model\n\nlearn a generator to approximate real data distribution\n\ngenerator shift / data-distribution shift\n\nReinforcement Learning\n\nmaximize accumulate rewards\n\nstate, action, reward and state transition dynamics shift", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "7", "text": "ent Learning\n\nmaximize accumulate rewards\n\nstate, action, reward and state transition dynamics shift\n\nFederated Learning\n\ndecentralized training without sharing data\n\nmodel average; non-i.i.d data; data-distribution shift\n\nTABLE II: \nBeneficial Forgetting: Comparisons among different problem settings.\n\nProblem Setting\n\nGoal\n\nMitigate Overfitting\n\nmitigate memorization of training data through selective forgetting\n\nDebias and Forget Irrelevant Information\n\nforget biased information to achieve better performance or remove irrelevant information to learn new tasks\n\nMachine Unlearning\n\nforget some specified training data to protect user privacy\n\nIn this survey, we classify forgetting in machine ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "8", "text": " specified training data to protect user privacy\n\nIn this survey, we classify forgetting in machine learning into: harmful forgetting and beneficial forgetting, based on the specific application scenarios. Harmful forgetting occurs when we desire the machine learning model to retain previously learned knowledge while adapting to new tasks, domains, or environments. In such scenarios, it is crucial to prevent knowledge forgetting. Conversely, there are many cases where beneficial forgetting becomes necessary. For example: (1) Overfitting to the training data hinders generalization. (2) Irrelevant and noisy information impedes the model’s ability to effectively learn new knowledge. (3) Pre-tra", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "9", "text": "nt and noisy information impedes the model’s ability to effectively learn new knowledge. (3) Pre-trained model contains private information that could potentially lead to privacy leakage. In these situations, forgetting becomes desirable as it serves several important purposes. Firstly, forgetting can mitigate overfitting, as it allows the model to forget irrelevant details and focus on the most pertinent patterns in the training data. Additionally, by discarding unnecessary information, forgetting facilitates the learning of new knowledge, as the model can make better use of its capacity to acquire and adapt to novel information. Lastly, forgetting helps protect privacy by discarding sensit", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "10", "text": "cquire and adapt to novel information. Lastly, forgetting helps protect privacy by discarding sensitive user information, ensuring that such data is not retained in the model’s memory.\n\n1.1 \nHarmful Forgetting\n\nHarmful forgetting has been observed not only in CL but also in various other research areas, including foundation model, domain adaptation, meta-learning, test-time adaptation, generative model, reinforcement learning and federated learning. While existing surveys have predominantly focused on forgetting in CL, this survey aims to fill the gap by providing an overview of forgetting across various learning scenarios.\n\nForgetting in these research fields can be attributed to various fa", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "11", "text": "oss various learning scenarios.\n\nForgetting in these research fields can be attributed to various factors. In continual learning, forgetting occurs due to the shift in data distribution across different tasks. In meta-learning, forgetting is a consequence of the shift in task distribution. In federated learning, forgetting is caused by the heterogeneity of data distribution among different clients, commonly known as client drift. In domain adaptation, forgetting happens because of domain shift. In test-time adaptation, forgetting is a result of adapting to the test data distribution during testing. In generative models, forgetting occurs due to the shift in the generator over time or when le", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "12", "text": "ting. In generative models, forgetting occurs due to the shift in the generator over time or when learning non-stationary data distribution. In reinforcement learning, forgetting can occur as a result of shifts in state, action, reward, and state transition dynamics over time. These changes in the underlying environment can lead to the loss or alteration of previously learned knowledge in reinforcement learning. In foundation models, forgetting can be attributed to: fine-tuning forgetting, incremental streaming data pre-training, and the utilization of foundation models for downstream CL tasks.\n\nTo facilitate comparisons of various settings related to forgetting, we present a comprehensive a", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "13", "text": ".\n\nTo facilitate comparisons of various settings related to forgetting, we present a comprehensive analysis of harmful forgetting in Table \nI\n.\n\nHarmful Forgetting Definition\n. We denote the performance on the test set \nX\nt\nsubscript\n𝑋\n𝑡\nX_{t}\nitalic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n when learning task/domain \nt\n𝑡\nt\nitalic_t\n with parameters \n𝜽\nt\nsubscript\n𝜽\n𝑡\n{\\bm{\\theta}}_{t}\nbold_italic_θ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n as \nℒ\n⁢\n(\n𝜽\nt\n,\nX\nt\n)\nℒ\nsubscript\n𝜽\n𝑡\nsubscript\n𝑋\n𝑡\n{\\mathcal{L}}({\\bm{\\theta}}_{t},X_{t})\ncaligraphic_L ( bold_italic_θ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )\n. We denote t", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "14", "text": "italic_t end_POSTSUBSCRIPT , italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )\n. We denote the performance on the test set \nX\nt\nsubscript\n𝑋\n𝑡\nX_{t}\nitalic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n after learning the last task/domain \nT\n𝑇\nT\nitalic_T\n with parameters \n𝜽\nT\nsubscript\n𝜽\n𝑇\n{\\bm{\\theta}}_{T}\nbold_italic_θ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT\n as \nℒ\n⁢\n(\n𝜽\nT\n,\nX\nt\n)\nℒ\nsubscript\n𝜽\n𝑇\nsubscript\n𝑋\n𝑡\n{\\mathcal{L}}({\\bm{\\theta}}_{T},X_{t})\ncaligraphic_L ( bold_italic_θ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT , italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )\n. Forgetting after learning task/domain \nT\n𝑇\nT\nitalic_T\n can then be defined as follows:\n\nD", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "15", "text": "SCRIPT )\n. Forgetting after learning task/domain \nT\n𝑇\nT\nitalic_T\n can then be defined as follows:\n\nDefinition 1.1\n (Forgetting)\n\nF\n=\n1\nT\n−\n1\n⁢\n∑\nt\n=\n1\nT\n(\nℒ\n⁢\n(\n𝜽\nT\n,\nX\nt\n)\n−\nℒ\n⁢\n(\n𝜽\nt\n,\nX\nt\n)\n)\n𝐹\n1\n𝑇\n1\nsuperscript\nsubscript\n𝑡\n1\n𝑇\nℒ\nsubscript\n𝜽\n𝑇\nsubscript\n𝑋\n𝑡\nℒ\nsubscript\n𝜽\n𝑡\nsubscript\n𝑋\n𝑡\nF=\\frac{1}{T-1}\\sum_{t=1}^{T}({\\mathcal{L}}({\\bm{\\theta}}_{T},X_{t})-{\\mathcal%\n{L}}({\\bm{\\theta}}_{t},X_{t}))\nitalic_F = divide start_ARG 1 end_ARG start_ARG italic_T - 1 end_ARG ∑ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( caligraphic_L ( bold_italic_θ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT , italic_X start_POSTSUBSCRIPT italic_t end_PO", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "16", "text": "alic_θ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT , italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) - caligraphic_L ( bold_italic_θ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) )\n\n(1)\n\nThis definition covers various learning scenarios in different settings. For example, for continual learning, \nℒ\n⁢\n(\n𝜽\nt\n,\nX\nt\n)\nℒ\nsubscript\n𝜽\n𝑡\nsubscript\n𝑋\n𝑡\n{\\mathcal{L}}({\\bm{\\theta}}_{t},X_{t})\ncaligraphic_L ( bold_italic_θ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )\n denotes the test set performance on task \nt\n𝑡\nt\nitalic_t\n. For reinforcement learning, \nℒ\n⁢\n(\n𝜽\nt\n,\nX\nt", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "17", "text": "otes the test set performance on task \nt\n𝑡\nt\nitalic_t\n. For reinforcement learning, \nℒ\n⁢\n(\n𝜽\nt\n,\nX\nt\n)\nℒ\nsubscript\n𝜽\n𝑡\nsubscript\n𝑋\n𝑡\n{\\mathcal{L}}({\\bm{\\theta}}_{t},X_{t})\ncaligraphic_L ( bold_italic_θ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )\n denotes the cumulative reward/average reward/discounted reward on task \nt\n𝑡\nt\nitalic_t\n. For meta-learning, \nℒ\n⁢\n(\n𝜽\nt\n,\nX\nt\n)\nℒ\nsubscript\n𝜽\n𝑡\nsubscript\n𝑋\n𝑡\n{\\mathcal{L}}({\\bm{\\theta}}_{t},X_{t})\ncaligraphic_L ( bold_italic_θ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )\n denotes the meta test set accuracy on task distribution ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "18", "text": "POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )\n denotes the meta test set accuracy on task distribution \nt\n𝑡\nt\nitalic_t\n. For generative model, \nℒ\n⁢\n(\n𝜽\nt\n,\nX\nt\n)\nℒ\nsubscript\n𝜽\n𝑡\nsubscript\n𝑋\n𝑡\n{\\mathcal{L}}({\\bm{\\theta}}_{t},X_{t})\ncaligraphic_L ( bold_italic_θ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )\n denotes the Frechet Inception Distance (FID) or Inception Score (IS).\n\n1.2 \nBeneficial Forgetting\n\nWhile the prevailing belief in most existing works is that forgetting is harmful, we have come to recognize that forgetting is a double-edged sword. There are many instances where it is advantageous to forget certain knowledge. For exa", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "19", "text": "-edged sword. There are many instances where it is advantageous to forget certain knowledge. For example: (1) selective forgetting could help mitigate overfitting; (2) to enhance model generalization or facilitate learning of new tasks/knowledge, it is imperative to eliminate biased or irrelevant information from previously learned knowledge; and (3) machine unlearning, which prevents data privacy leakage.\n\nFirst, overfitting has remained a fundamental challenge in machine learning, as it arises when a model excessively memorizes the training data but struggles to generalize effectively to new, unseen test data. To improve generalization, it is crucial for the model to avoid the mere memoriz", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "20", "text": ", unseen test data. To improve generalization, it is crucial for the model to avoid the mere memorization of training data and instead should prioritize learning the true underlying relationship between the input data and corresponding labels.\nOne important technique to enhance generalization is selective forgetting. By selectively discarding irrelevant or noisy information learned from training data, the model can focus on the most pertinent patterns and features, leading to improved generalization performance on unseen data.\n\nSecond, when learning new tasks or knowledge, previously acquired knowledge may not always be helpful for improving learning on new information. When a model contains", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "21", "text": "knowledge may not always be helpful for improving learning on new information. When a model contains outdated or unrelated knowledge, it can hinder its ability to effectively learn and generalize from new data. In such situations, it is necessary to discard irrelevant information from the model’s memory. By freeing up capacity within the model, it becomes more receptive and adaptive to acquiring new knowledge.\nThe process of discarding irrelevant information is crucial for preventing interference between old and new knowledge.\n\nLastly, model users may request the removal of their training data from both the database and the pre-trained model, exercising their Right to Be Forgotten \n[\n10\n]\n. ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "22", "text": " from both the database and the pre-trained model, exercising their Right to Be Forgotten \n[\n10\n]\n. To address this, researchers have developed machine unlearning, which allows models to intentionally forget unwanted private data. Additionally, some privacy attacks exploit the model’s tendency to memorize data to extract private information. Membership inference attacks \n[\n11\n]\n can identify whether a specific data point was part of the training data for a pre-trained model. Intentional forgetting of private data helps protect privacy and prevent information leakage in such cases.\n\nTo facilitate comparisons, we also provide a comparative analysis in Table \nII\n for beneficial forgetting, enco", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "23", "text": "te comparisons, we also provide a comparative analysis in Table \nII\n for beneficial forgetting, encompassing the above mentioned diverse settings for reference.\n\n1.3 \nChallenges in Addressing Forgetting\n\nAddressing forgetting faces numerous challenges that vary across different research fields. These challenges include:\n\nData Availability\n:\nData availability is a significant challenge for addressing forgetting in various scenarios. Limited access to previous task data, due to storage constraints or privacy concerns, complicates continual learning, meta-learning, domain adaptation, generative models, and reinforcement learning. Additionally, some scenarios, like federated learning, prohibit u", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "24", "text": "odels, and reinforcement learning. Additionally, some scenarios, like federated learning, prohibit using raw data, as only the model parameters are shared with a central server.\n\nResource Constraints\n: Resource-limited environments, such as those with constraints on memory and computation, present challenges in effectively addressing forgetting. In online continual learning and meta-learning, where data or tasks are typically processed only once, these challenges are particularly pronounced.\nFurthermore, online learning often operates in resource-constrained environments with limited memory or computation capabilities. These constraints pose additional hurdles for addressing forgetting.\n\nAda", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "25", "text": " computation capabilities. These constraints pose additional hurdles for addressing forgetting.\n\nAdaption to New Environments/Distribution\n: In continual learning, foundation models, reinforcement learning, domain adaptation, test-time adaptation, meta-learning, and generative models, the target environment or data distribution can change over time. The learning agent must adapt to new scenarios, which can happen during training or testing. However, the agent often forgets previously acquired knowledge or loses performance on earlier tasks due to the data distribution shift.\n\nTask Interference/Inconsistency\n:\nConflicting goals among different tasks can cause task interference, making it hard", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "26", "text": "/Inconsistency\n:\nConflicting goals among different tasks can cause task interference, making it hard to prevent forgetting in continual learning and federated learning. In continual learning, sequential tasks may conflict, making it difficult for the network to balance performance across multiple tasks and exacerbating forgetting. In federated learning, models trained on different clients can show inconsistencies \n[\n12\n]\n due to heterogeneous data distributions, leading to client interference and further worsening the forgetting problem.\n\nPrivacy-Leakage Prevention\n:\nIn some cases, retaining old knowledge can raise privacy concerns by unintentionally exposing private information. To address ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "27", "text": "ld knowledge can raise privacy concerns by unintentionally exposing private information. To address these risks and prevent the disclosure of sensitive data, the focus should be on forgetting or erasing training data traces rather than memorizing them. This challenge is central to machine unlearning, which aims to effectively remove training data traces from machine learning models \n[\n13\n]\n.\n\n1.4 \nSurvey Scope, Contributions and Organization\n\nSurvey Scope\n.\nOur main objective is to give a comprehensive overview of forgetting in key research areas where it is significant. By exploring these fields, we aim to highlight the existence and impact of forgetting in these domains.\n\nOur contributions", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "28", "text": "lds, we aim to highlight the existence and impact of forgetting in these domains.\n\nOur contributions can be summarized into three fold:\n\n•\n\nWe provide a more systematic survey on CL compared to existing surveys. Our survey includes a more systematic categorization of CL problem settings and methods.\n\n•\n\nIn addition to CL, our survey extends its scope to encompass forgetting in other research fields. This broader coverage provides a comprehensive understanding of forgetting across various research fields.\n\n•\n\nOur survey, in contrast to existing surveys on CL, reveals that forgetting can be viewed as a double-edged sword. We emphasize that forgetting can also have beneficial implications in pr", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "29", "text": "ed as a double-edged sword. We emphasize that forgetting can also have beneficial implications in privacy-preserving scenarios.\n\nOrganization\n.\nThe structure of this paper is as follows.\nIn Sections \n2\n-\n8\n, we provide a comprehensive survey on harmful forgetting in continual learning, foundation model, domain adaptation, test-time adaptation, meta-learning, generative model, reinforcement learning, and federated learning. Each section explores the occurrence and impact of forgetting within these specific fields.\nIn Section \n9\n, we delve into the concept of beneficial forgetting. This section highlights the positive aspects of forgetting in specific learning scenarios. In Section \n10\n, we pr", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "30", "text": "highlights the positive aspects of forgetting in specific learning scenarios. In Section \n10\n, we present the current research trends and offer insights into the potential future developments.\n\n2 \nForgetting in Continual Learning\n\nTABLE III: \nContent outline in CL. Based on different problem setting categorization criteria, the CL setting can be classified into various scenarios, as presented in the following table:\n\nSection\n\nProblem Setting\n\nCategorization Criterion\n\nSection \n2.1\n\nTask-aware and Task-free CL\n\nwhether explicit task splits/information are available or not during training\n\nSection \n2.2\n\nOnline CL\n\nthe model processes the data in a single pass or multiple passes\n\nSection \n2.3\n\n", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "31", "text": "on \n2.2\n\nOnline CL\n\nthe model processes the data in a single pass or multiple passes\n\nSection \n2.3\n\nSemi-supervised, Few-shot and Unsupervised CL\n\nthe amount of labeled data used in CL\n\nThe goal of continual learning (CL) is to learn on a sequence of tasks \n𝒯\n1\n,\n𝒯\n2\n,\n⋯\n,\n𝒯\nN\nsubscript\n𝒯\n1\nsubscript\n𝒯\n2\n⋯\nsubscript\n𝒯\n𝑁\n{\\mathcal{T}}_{1},{\\mathcal{T}}_{2},\\cdots,{\\mathcal{T}}_{N}\ncaligraphic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , caligraphic_T start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ⋯ , caligraphic_T start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT\n without forgetting the knowledge on previous tasks. It can be formulated with the following optimization objective.\nSuppose when learning t", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "32", "text": "vious tasks. It can be formulated with the following optimization objective.\nSuppose when learning task \nt\n𝑡\nt\nitalic_t\n, the goal is to minimize the risk on all the seen tasks so far, i.e.,\n\nℒ\n⁢\n(\n𝜽\nt\n)\n=\n∑\nt\n=\n1\nN\n𝔼\n(\n𝒙\n,\ny\n)\n∼\n𝒟\n𝒯\nt\n⁢\nℒ\n𝜽\nt\n⁢\n(\n𝒙\n,\ny\n)\n,\nℒ\nsubscript\n𝜽\n𝑡\nsuperscript\nsubscript\n𝑡\n1\n𝑁\nsubscript\n𝔼\nsimilar-to\n𝒙\n𝑦\nsubscript\n𝒟\nsubscript\n𝒯\n𝑡\nsubscript\nℒ\nsubscript\n𝜽\n𝑡\n𝒙\n𝑦\n{\\mathcal{L}}({\\bm{\\theta}}_{t})=\\sum_{t=1}^{N}{\\mathbb{E}}_{({\\bm{x}},y)\\sim{%\n\\mathcal{D}}_{{\\mathcal{T}}_{t}}}{\\mathcal{L}}_{{\\bm{\\theta}}_{t}}({\\bm{x}},y),\ncaligraphic_L ( bold_italic_θ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) = ∑ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "33", "text": "c_t end_POSTSUBSCRIPT ) = ∑ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT blackboard_E start_POSTSUBSCRIPT ( bold_italic_x , italic_y ) ∼ caligraphic_D start_POSTSUBSCRIPT caligraphic_T start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT bold_italic_θ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( bold_italic_x , italic_y ) ,\n\n(2)\n\nwhere \n𝔼\n𝔼\n{\\mathbb{E}}\nblackboard_E\n denotes expectation, \n𝜽\nt\nsubscript\n𝜽\n𝑡\n{\\bm{\\theta}}_{t}\nbold_italic_θ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n are parameters when learning task \nt\n𝑡\nt\nitalic_t\n, and \n𝒟\n𝒯\nt\nsubs", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "34", "text": "RIPT italic_t end_POSTSUBSCRIPT\n are parameters when learning task \nt\n𝑡\nt\nitalic_t\n, and \n𝒟\n𝒯\nt\nsubscript\n𝒟\nsubscript\n𝒯\n𝑡\n{\\mathcal{D}}_{{\\mathcal{T}}_{t}}\ncaligraphic_D start_POSTSUBSCRIPT caligraphic_T start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT\n represents the training data of task \nt\n𝑡\nt\nitalic_t\n.\n\nThe CL problem can be categorized in several different ways. Firstly, according to whether explicit task splits/information are available or not during training stage, CL can be divided into \ntask-aware (task-based) and task-free (task-agnostic)\n scenarios \n[\n14\n]\n. Task-aware CL can be further classified into task/domain/class incremental learning \n[\n3\n]\n, depending on w", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "35", "text": "are CL can be further classified into task/domain/class incremental learning \n[\n3\n]\n, depending on whether the task ID is known during testing stage. Among them, task-incremental learning knows the task ID during testing, while domain-incremental learning and class-incremental learning do not know the task ID during the testing phase. In particular, the label space of domain-incremental learning is the same, while other settings have independent label spaces. Addressing forgetting in task-aware CL is relatively straightforward due to the availability of task information. With knowledge of the specific tasks involved, CL learner can utilize task-specific cues or labels to guide its learning p", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "36", "text": "specific tasks involved, CL learner can utilize task-specific cues or labels to guide its learning process and manage forgetting.\nHowever, addressing forgetting in task-free CL is more challenging since there are no explicit task splits or task-specific information available. As a result, the learning system must autonomously identify and adapt to changes or shifts in the data distribution without any task-specific cues or labels. This requires the development of robust and adaptive mechanisms that can detect and respond to changes in the data distribution.\n\nSecondly, depending on whether the model processes the data in a single pass or multiple passes, CL can be categorized as \nonline and o", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "37", "text": "model processes the data in a single pass or multiple passes, CL can be categorized as \nonline and offline CL\n. Offline CL has been extensively studied due to its availability of abundant computing and storage resources. However, online CL presents unique challenges. In online CL, the agent has limited access to past data and experiences, which restricts the opportunities to revisit and reinforce previously learned tasks.\nFurthermore, online learning often operates in resource-constrained environments with limited memory or processing capabilities. These resource limitations pose additional hurdles for addressing forgetting in online CL.\n\nLastly, according to the amount of labeled data used ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "38", "text": "rdles for addressing forgetting in online CL.\n\nLastly, according to the amount of labeled data used in CL, they could be categorized into \nsupervised, semi-supervised, few-shot, and unsupervised CL\n.\nSupervised CL is generally considered the easiest case since the availability of labeled data provides clear task boundaries and evaluation signals. However, challenges arise in other forms of CL.\nFor semi-supervised CL: the challenge lies in selecting useful knowledge from unlabeled data to mitigate forgetting. Not all unlabeled data may be beneficial for addressing forgetting, making the selection process challenging.\nIn few-shot CL: the scarcity of labeled data requires the learning agent to ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "39", "text": "on process challenging.\nIn few-shot CL: the scarcity of labeled data requires the learning agent to effectively utilize the available information to minimize forgetting and adapt to new tasks.\nIn unsupervised CL: unsupervised CL is the most challenging due to the absence of explicit task boundaries. Defining when a new task begins and differentiating it from previous tasks becomes difficult.\nFurthermore, the absence of labeled data in unsupervised CL results in a scarcity of feedback and evaluation signals for measuring forgetting.\n\nIt is important to note that the terms CL and incremental learning (IL) are often used interchangeably when addressing learning from non-stationary data distribu", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "40", "text": "rning (IL) are often used interchangeably when addressing learning from non-stationary data distributions, as described in \n[\n3\n]\n. The key objective of CL and IL is to enable models to learn continuously by updating in stages as new data becomes available, ensuring that they can acquire new knowledge while retaining previously learned information. Traditional online learning (OL), by contrast, represents a special case of IL, where the model processes data streams in real time. In OL, the model is updated immediately upon receiving new data, typically handling one sample (or a small batch) at a time from a stationary data distribution/single task. The primary goal of OL is efficient learnin", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "41", "text": " a time from a stationary data distribution/single task. The primary goal of OL is efficient learning rather than mitigating forgetting. This contrasts with CL and IL, where models are updated across multiple epochs and often adapt to changing, non-stationary data distributions.\n\nBelow, we present the details of each CL problem setting and its corresponding related works. To make content organization clear, we provide a Table \nIII\n to summarize the problem setting categorization in the following sections.\n\n2.1 \nTask-Aware and Task-Free CL\n\n2.1.1 \nTask-aware CL\n\nTask-aware CL focuses on addressing scenarios where explicit task definitions, such as task IDs, are available during the CL process", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "42", "text": "ing scenarios where explicit task definitions, such as task IDs, are available during the CL process. The three most common CL scenarios within task-aware settings are task-incremental learning, domain-incremental learning, and class-incremental learning \n[\n3\n]\n.\nIn domain-incremental learning, tasks sequentially arrive with the same label space but different input data distributions. This means that the tasks share a common set of labels or categories, but the distribution of the input data may vary across tasks.\nTask-incremental learning refers to the scenario where tasks arrive sequentially, and each task has its own disjoint label space. During testing, the presence of task IDs allows th", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "43", "text": ", and each task has its own disjoint label space. During testing, the presence of task IDs allows the model to identify the specific task at hand.\nClass-incremental learning does not provide task IDs during testing. Instead, the model needs to incrementally learn new classes without forgetting previously learned classes.\n\nProblem Setup:\n We consider the standard CL problem of learning a sequence of \nN\n𝑁\nN\nitalic_N\n tasks denoted as \n𝒟\nt\n⁢\nr\n=\n{\n𝒟\n1\nt\n⁢\nr\n,\n𝒟\n2\nt\n⁢\nr\n,\n⋯\n,\n𝒟\nN\nt\n⁢\nr\n}\nsuperscript\n𝒟\n𝑡\n𝑟\nsuperscript\nsubscript\n𝒟\n1\n𝑡\n𝑟\nsuperscript\nsubscript\n𝒟\n2\n𝑡\n𝑟\n⋯\nsuperscript\nsubscript\n𝒟\n𝑁\n𝑡\n𝑟\n{\\mathcal{D}}^{tr}=\\{{\\mathcal{D}}_{1}^{tr},{\\mathcal{D}}_{2}^{tr},\\cdots,{%\n\\mathcal{D}}_{N}^{tr}\\}\n", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "44", "text": "\\mathcal{D}}^{tr}=\\{{\\mathcal{D}}_{1}^{tr},{\\mathcal{D}}_{2}^{tr},\\cdots,{%\n\\mathcal{D}}_{N}^{tr}\\}\ncaligraphic_D start_POSTSUPERSCRIPT italic_t italic_r end_POSTSUPERSCRIPT = { caligraphic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_r end_POSTSUPERSCRIPT , caligraphic_D start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_r end_POSTSUPERSCRIPT , ⋯ , caligraphic_D start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_r end_POSTSUPERSCRIPT }\n. The training data of \nk\n𝑘\nk\nitalic_k\n-th task \n𝒟\nk\nt\n⁢\nr\nsuperscript\nsubscript\n𝒟\n𝑘\n𝑡\n𝑟\n{\\mathcal{D}}_{k}^{tr}\ncaligraphic_D start_POSTSUBSCRIPT italic_k end_POST", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "45", "text": "rscript\nsubscript\n𝒟\n𝑘\n𝑡\n𝑟\n{\\mathcal{D}}_{k}^{tr}\ncaligraphic_D start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_r end_POSTSUPERSCRIPT\n consists of a set of triplets \n{\n(\n𝒙\ni\nk\n,\ny\ni\nk\n,\n𝒯\nk\n)\ni\n=\n1\nn\nk\n}\nsuperscript\nsubscript\nsuperscript\nsubscript\n𝒙\n𝑖\n𝑘\nsuperscript\nsubscript\n𝑦\n𝑖\n𝑘\nsubscript\n𝒯\n𝑘\n𝑖\n1\nsubscript\n𝑛\n𝑘\n\\{({\\bm{x}}_{i}^{k},y_{i}^{k},{\\mathcal{T}}_{k})_{i=1}^{n_{k}}\\}\n{ ( bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT , italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT , caligraphic_T start_POSTSUBSCRIPT italic_k end_POSTSUBSCRI", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "46", "text": "UPERSCRIPT italic_k end_POSTSUPERSCRIPT , caligraphic_T start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUPERSCRIPT }\n, where \n𝒙\ni\nk\nsuperscript\nsubscript\n𝒙\n𝑖\n𝑘\n{\\bm{x}}_{i}^{k}\nbold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT\n is the \ni\n𝑖\ni\nitalic_i\n-th data example, \ny\ni\nk\nsuperscript\nsubscript\n𝑦\n𝑖\n𝑘\ny_{i}^{k}\nitalic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT\n is the data label associated with \n𝒙\ni\nk\nsuperscript\nsubscript\n𝒙\n𝑖\n𝑘\n{\\bm{x}}", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "47", "text": "k end_POSTSUPERSCRIPT\n is the data label associated with \n𝒙\ni\nk\nsuperscript\nsubscript\n𝒙\n𝑖\n𝑘\n{\\bm{x}}_{i}^{k}\nbold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT\n, and \n𝒯\nk\nsubscript\n𝒯\n𝑘\n{\\mathcal{T}}_{k}\ncaligraphic_T start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT\n is the task identifier. The goal is to learn a neural network with parameters \n𝜽\n𝜽\n{\\bm{\\theta}}\nbold_italic_θ\n, i.e., \nf\n𝜽\nsubscript\n𝑓\n𝜽\nf_{{\\bm{\\theta}}}\nitalic_f start_POSTSUBSCRIPT bold_italic_θ end_POSTSUBSCRIPT\n, on \n𝒟\nt\n⁢\nr\nsuperscript\n𝒟\n𝑡\n𝑟\n{\\mathcal{D}}^{tr}\ncaligraphic_D start_POSTSUPERSCRIPT italic_t italic_r end_POSTSUPERSCRIPT\n so that it performs well on the", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "48", "text": "aphic_D start_POSTSUPERSCRIPT italic_t italic_r end_POSTSUPERSCRIPT\n so that it performs well on the test set of all the learned tasks \n𝒟\nt\n⁢\ne\n=\n{\n𝒟\n1\nt\n⁢\ne\n,\n𝒟\n2\nt\n⁢\ne\n,\n⋯\n,\n𝒟\nN\nt\n⁢\ne\n}\nsuperscript\n𝒟\n𝑡\n𝑒\nsuperscript\nsubscript\n𝒟\n1\n𝑡\n𝑒\nsuperscript\nsubscript\n𝒟\n2\n𝑡\n𝑒\n⋯\nsuperscript\nsubscript\n𝒟\n𝑁\n𝑡\n𝑒\n{\\mathcal{D}}^{te}=\\{{\\mathcal{D}}_{1}^{te},{\\mathcal{D}}_{2}^{te},\\cdots,{%\n\\mathcal{D}}_{N}^{te}\\}\ncaligraphic_D start_POSTSUPERSCRIPT italic_t italic_e end_POSTSUPERSCRIPT = { caligraphic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_e end_POSTSUPERSCRIPT , caligraphic_D start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_e end_POSTSUPER", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "49", "text": "phic_D start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_e end_POSTSUPERSCRIPT , ⋯ , caligraphic_D start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_e end_POSTSUPERSCRIPT }\n without forgetting the knowledge of previous tasks.\n\nFigure 1: \nCategorization of existing continual learning approach.\n\nExisting methods on task-aware CL have explored five main branches: memory-based, architecture-based, regularization-based, subspace-based, and Bayesian-based methods. An overview of these branches is provided in Figure \n1\n. For a more comprehensive description of the methods within each category, please refer to Appendix \nA.1\n. Below, we p", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "50", "text": "hensive description of the methods within each category, please refer to Appendix \nA.1\n. Below, we provide a brief description of each class method.\n\nMemory-based Method\n\nMemory-based method keeps a \nmemory buffer\n that stores the data examples from previous tasks and replays those examples during learning new tasks. It can be further categorized into: raw memory replay; memory sample selection; generative replay; and compressed memory replay. Next, we discuss each direction in detail.\n(1) \nRaw Sample Replay:\n These methods randomly save a small amount of raw data from previous tasks and train the model together with the new task data. When the new task updates the model, the old task data i", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "51", "text": " the model together with the new task data. When the new task updates the model, the old task data is used as a constraint \n[\n15\n, \n16\n]\n or directly mixed with the new data to form a batch \n[\n17\n]\n to update the model, thereby alleviating forgetting.\n(2) \nMemory Sample Selection:\n Randomly selecting samples for replay ignores the amount of information in each sample, which can lead to suboptimal performance \n[\n18\n, \n19\n]\n. Therefore, \nheuristic selection\n selects samples to be stored according to certain rules. For example, select the representative sample closest to the cluster center \n[\n20\n]\n, the samples with higher diversity \n[\n21\n, \n22\n]\n, or the difficult sample closer to the decision", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "52", "text": "]\n, the samples with higher diversity \n[\n21\n, \n22\n]\n, or the difficult sample closer to the decision boundary \n[\n23\n, \n24\n]\n.\n(3) \nGenerative Replay:\n When privacy concerns restrict the storage of raw memory data, generative replay provides an alternative approach in CL to replay previous task data. The main concept behind generative replay is to train a generative model capable of capturing and remembering the data distribution from previous tasks. The representative works include GAN-based \n[\n25\n, \n26\n]\n, AutoEncoder-based \n[\n27\n]\n, Diffusion-based \n[\n28\n]\n, and Model-inversion \n[\n29\n]\n.\n(4) \nCompressed Memory Replay:\n In scenarios with strict storage constraints on edge devices, memory ef", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "53", "text": " \nCompressed Memory Replay:\n In scenarios with strict storage constraints on edge devices, memory efficiency becomes a critical consideration. Existing works store feature representations \n[\n30\n, \n31\n]\n or low-fidelity images \n[\n32\n, \n33\n]\n instead of original images, or learning a set of condensed images \n[\n34\n, \n35\n, \n36\n]\n using dataset distillation \n[\n37\n]\n.\n\nArchitecture-based Method\n\nArchitecture-based methods in CL \n[\n38\n, \n39\n, \n40\n]\n involve updating the network architecture during the learning process to retain previously acquired knowledge. These methods aim to adapt the model’s architecture to acquire new tasks while preserving the knowledge from previous tasks.\nBased on whether ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "54", "text": "hitecture to acquire new tasks while preserving the knowledge from previous tasks.\nBased on whether the model parameters expand with the number of tasks, architecture-based methods can be categorized into two types: fixed-capacity and capacity-increasing methods.\n(1) \nFixed-Capacity\n: In these methods, the amount of CL model’s parameters does not increase with the number of tasks, and each task selects a sub-network from the CL model to achieve knowledge transfer and reduce the forgetting caused by sub-network updates. Common subnetwork selection techniques include masking \n[\n41\n, \n42\n, \n43\n]\n, and pruning \n[\n44\n, \n45\n, \n46\n]\n.\n(2) \nCapacity-Increasing\n: As the number of tasks increases, fix", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "55", "text": ", and pruning \n[\n44\n, \n45\n, \n46\n]\n.\n(2) \nCapacity-Increasing\n: As the number of tasks increases, fixed-capacity CL models may face limitations in accommodating new tasks. To overcome this challenge, dynamic capacity methods are proposed \n[\n38\n, \n40\n, \n47\n, \n48\n]\n. These methods ensure that old tasks are not forgotten and adapt to new tasks by introducing new task-specific parameters for each new task, while freezing parameters related to old tasks.\n\nRegularization-based Method\n\nThese methods in CL involve the addition of regularization loss terms to the training objective to prevent forgetting previously learned knowledge \n[\n49\n, \n50\n, \n51\n]\n.\nIt can be further divided into two subcategories", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "56", "text": " previously learned knowledge \n[\n49\n, \n50\n, \n51\n]\n.\nIt can be further divided into two subcategories: penalizing important parameter updates and knowledge distillation using a previous model as a teacher.\n(1) \nPenalize Parameter Updates:\n These methods use the Fisher information matrix \n[\n49\n]\n or the cumulative update amount of parameters \n[\n52\n]\n as a measure of the importance of old task parameters. On the one hand, when new tasks update important parameters, a large penalty is imposed in order to keep the knowledge of old tasks from being forgotten. On the other hand, imposing a small penalty on unimportant parameter updates helps learn new task’s knowledge \n[\n50\n, \n53\n, \n23\n]\n.\n(2) \nKno", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "57", "text": "lty on unimportant parameter updates helps learn new task’s knowledge \n[\n50\n, \n53\n, \n23\n]\n.\n(2) \nKnowledge-Distillation-Based:\n Several methods in CL incorporate a knowledge distillation \n[\n54\n]\n loss between the network of the previous task (referred to as the teacher) and the network of the current task (referred to as the student) to mitigate forgetting \n[\n55\n, \n56\n, \n57\n]\n. It should be mentioned that the ideal scenario would involve using raw data from old tasks to extract the knowledge of the teacher model and refine it into the student model. However, accessing raw data of old tasks is often not feasible due to data privacy concerns. Therefore, existing methods utilize proxy data, suc", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "58", "text": "often not feasible due to data privacy concerns. Therefore, existing methods utilize proxy data, such as new task data \n[\n55\n]\n or large-scale unlabeled data \n[\n58\n]\n, as a substitute for distillation.\n\nSubspace-based Method\n\nSubspace-based methods in CL aim to address the issue of interference between multiple tasks by conducting learning in separate and disjoint subspaces, thus reducing old task forgetting. Subspace-based methods can be categorized into two types based on how the subspaces are constructed:\n(1) \nOrthogonal Gradient Subspace\n: These methods require that the parameter update direction of the new task is orthogonal to the gradient subspace of the old tasks \n[\n59\n, \n60\n, \n61\n]\n", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "59", "text": "rection of the new task is orthogonal to the gradient subspace of the old tasks \n[\n59\n, \n60\n, \n61\n]\n, ensuring minimal interference between tasks.\n(2) \nOrthogonal Feature Subspace\n: These require that the parameter update direction of the new task is orthogonal to the subspace spanned by the input(feature) of the old tasks \n[\n62\n, \n63\n, \n64\n, \n65\n, \n66\n]\n.\n\nWe illustrate the working principle of the subspace-based methods (i.e., the orthogonal projection methods) in Fig. \n2\n.\nSpecifically, we define the core subspace (CS) spanned by task 1 in the \nl\nt\n⁢\nh\nsuperscript\n𝑙\n𝑡\nℎ\nl^{th}\nitalic_l start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT\n layer as \nS\nl\nsuperscript\n𝑆\n𝑙\n\\small S^{l}\n", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "60", "text": "t_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT\n layer as \nS\nl\nsuperscript\n𝑆\n𝑙\n\\small S^{l}\nitalic_S start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT\n, constructed from the gradients or features of task 1. The orthogonal space of the core subspace is denoted as the residual subspace (RS). When a new task 2 updates the network in the \nl\nt\n⁢\nh\nsuperscript\n𝑙\n𝑡\nℎ\nl^{th}\nitalic_l start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT\n layer with parameters \n𝜽\nl\nsuperscript\n𝜽\n𝑙\n\\small{\\bm{\\theta}}^{l}\nbold_italic_θ start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT\n, the original gradient direction \n𝐠\n𝜽\nl\n(\n2\n)\nsuperscript\nsubscript\n𝐠\nsuperscript\n𝜽\n𝑙\n2\n\\small\\mathbf{g}_{{\\bm{\\theta}", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "61", "text": "ient direction \n𝐠\n𝜽\nl\n(\n2\n)\nsuperscript\nsubscript\n𝐠\nsuperscript\n𝜽\n𝑙\n2\n\\small\\mathbf{g}_{{\\bm{\\theta}}^{l}}^{(2)}\nbold_g start_POSTSUBSCRIPT bold_italic_θ start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT\n is decomposed into CS and RS components. Only the gradient component in the RS, given by \n𝐠\n𝜽\nl\n(\n2\n)\n−\nProj\nS\nl\n⁢\n(\n𝐠\n𝜽\nl\n(\n2\n)\n)\nsuperscript\nsubscript\n𝐠\nsuperscript\n𝜽\n𝑙\n2\nsubscript\nProj\nsuperscript\n𝑆\n𝑙\nsuperscript\nsubscript\n𝐠\nsuperscript\n𝜽\n𝑙\n2\n\\small\\mathbf{g}_{{\\bm{\\theta}}^{l}}^{(2)}-\\text{Proj}_{S^{l}}(\\mathbf{g}_{{%\n\\bm{\\theta}}^{l}}^{(2)})\nbold_g start_POSTSUBSCRIPT bold_italic_θ start_POSTSUPERSCRIPT italic_l end_POS", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "62", "text": "\\theta}}^{l}}^{(2)})\nbold_g start_POSTSUBSCRIPT bold_italic_θ start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT - Proj start_POSTSUBSCRIPT italic_S start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( bold_g start_POSTSUBSCRIPT bold_italic_θ start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT )\n, is used to update the parameter \n𝜽\nl\nsuperscript\n𝜽\n𝑙\n\\small{\\bm{\\theta}}^{l}\nbold_italic_θ start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT\n.\n\nFigure 2: \nAn illustration of the principle of orthogonal projection method.\n\nNext, we demonstrate why subs", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "63", "text": "2: \nAn illustration of the principle of orthogonal projection method.\n\nNext, we demonstrate why subspace-based approaches (e.g., \n[\n63\n, \n65\n, \n67\n]\n) can alleviate the forgetting problem. Let the network’s weight after training on task 1 be \n𝜽\n1\nl\nsuperscript\nsubscript\n𝜽\n1\n𝑙\n\\small{\\bm{\\theta}}_{1}^{l}\nbold_italic_θ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT\n, and the weight update for task 2 be \nΔ\n⁢\n𝜽\n2\nl\nΔ\nsuperscript\nsubscript\n𝜽\n2\n𝑙\n\\small\\Delta{\\bm{\\theta}}_{2}^{l}\nroman_Δ bold_italic_θ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT\n, resulting in the network’s weight after training on task 2 as ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "64", "text": "SCRIPT italic_l end_POSTSUPERSCRIPT\n, resulting in the network’s weight after training on task 2 as \n𝜽\n2\nl\n=\n𝜽\n1\nl\n+\nΔ\n⁢\n𝜽\n2\nl\nsuperscript\nsubscript\n𝜽\n2\n𝑙\nsuperscript\nsubscript\n𝜽\n1\n𝑙\nΔ\nsuperscript\nsubscript\n𝜽\n2\n𝑙\n\\small{\\bm{\\theta}}_{2}^{l}={\\bm{\\theta}}_{1}^{l}+\\Delta{\\bm{\\theta}}_{2}^{l}\nbold_italic_θ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT = bold_italic_θ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT + roman_Δ bold_italic_θ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT\n.\nClearly, the input sample \n𝒙\n1\n,\ni\nl\nsuperscript\nsubscript\n𝒙\n1\n𝑖\n𝑙\n\\small\\boldsy", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "65", "text": "d_POSTSUPERSCRIPT\n.\nClearly, the input sample \n𝒙\n1\n,\ni\nl\nsuperscript\nsubscript\n𝒙\n1\n𝑖\n𝑙\n\\small\\boldsymbol{x}_{1,i}^{l}\nbold_italic_x start_POSTSUBSCRIPT 1 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT\n from task 1 lies in the subspace \nS\nl\nsuperscript\n𝑆\n𝑙\n\\small S^{l}\nitalic_S start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT\n spanned by task 1. Since the update for task 2 is performed along the subspace orthogonal to \nS\nl\nsuperscript\n𝑆\n𝑙\n\\small S^{l}\nitalic_S start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT\n, we have \nΔ\n⁢\n𝜽\n2\nl\n⁢\n𝒙\n1\n,\ni\nl\n=\n0\nΔ\nsuperscript\nsubscript\n𝜽\n2\n𝑙\nsuperscript\nsubscript\n𝒙\n1\n𝑖\n𝑙\n0\n\\Delta{\\bm{\\theta}}_{2}^{l}\\boldsymbol{x}_{1,i}^{l}", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "66", "text": "\nsubscript\n𝜽\n2\n𝑙\nsuperscript\nsubscript\n𝒙\n1\n𝑖\n𝑙\n0\n\\Delta{\\bm{\\theta}}_{2}^{l}\\boldsymbol{x}_{1,i}^{l}=0\nroman_Δ bold_italic_θ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT bold_italic_x start_POSTSUBSCRIPT 1 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT = 0\n. In other words, if task 2 updates are restricted to the direction orthogonal to the subspace spanned by task 1, we ensure that \n𝜽\n2\nl\n⁢\n𝒙\n1\n,\ni\nl\n=\n𝜽\n1\nl\n⁢\n𝒙\n1\n,\ni\nl\nsuperscript\nsubscript\n𝜽\n2\n𝑙\nsuperscript\nsubscript\n𝒙\n1\n𝑖\n𝑙\nsuperscript\nsubscript\n𝜽\n1\n𝑙\nsuperscript\nsubscript\n𝒙\n1\n𝑖\n𝑙\n\\small{\\bm{\\theta}}_{2}^{l}\\boldsymbol{x}_{1,i}^{l}={\\bm{\\theta}}_{1}^{l}%\n\\bold", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "67", "text": "t\nsubscript\n𝒙\n1\n𝑖\n𝑙\n\\small{\\bm{\\theta}}_{2}^{l}\\boldsymbol{x}_{1,i}^{l}={\\bm{\\theta}}_{1}^{l}%\n\\boldsymbol{x}_{1,i}^{l}\nbold_italic_θ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT bold_italic_x start_POSTSUBSCRIPT 1 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT = bold_italic_θ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT bold_italic_x start_POSTSUBSCRIPT 1 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT\n, thereby preventing forgetting. The formal statement is as follows:\n\n𝜽\n2\nl\n⁢\n𝒙\n1\n,\ni\nl\n=\n(\n𝜽\n1\nl\n+\nΔ\n⁢\n𝜽\n2\nl\n)\n⁢\n𝒙\n1\n,\ni\nl\n=\n𝜽\n1\nl\n⁢\n𝒙\n", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "68", "text": " formal statement is as follows:\n\n𝜽\n2\nl\n⁢\n𝒙\n1\n,\ni\nl\n=\n(\n𝜽\n1\nl\n+\nΔ\n⁢\n𝜽\n2\nl\n)\n⁢\n𝒙\n1\n,\ni\nl\n=\n𝜽\n1\nl\n⁢\n𝒙\n1\n,\ni\nl\n+\nΔ\n⁢\n𝜽\n2\nl\n⁢\n𝒙\n1\n,\ni\nl\n=\n𝜽\n1\nl\n⁢\n𝒙\n1\n,\ni\nl\n.\nsuperscript\nsubscript\n𝜽\n2\n𝑙\nsuperscript\nsubscript\n𝒙\n1\n𝑖\n𝑙\nsuperscript\nsubscript\n𝜽\n1\n𝑙\nΔ\nsuperscript\nsubscript\n𝜽\n2\n𝑙\nsuperscript\nsubscript\n𝒙\n1\n𝑖\n𝑙\nsuperscript\nsubscript\n𝜽\n1\n𝑙\nsuperscript\nsubscript\n𝒙\n1\n𝑖\n𝑙\nΔ\nsuperscript\nsubscript\n𝜽\n2\n𝑙\nsuperscript\nsubscript\n𝒙\n1\n𝑖\n𝑙\nsuperscript\nsubscript\n𝜽\n1\n𝑙\nsuperscript\nsubscript\n𝒙\n1\n𝑖\n𝑙\n\\small{\\bm{\\theta}}_{2}^{l}\\boldsymbol{x}_{1,i}^{l}=\\left({\\bm{\\theta}}_{1}^{l%\n}+\\Delta{\\bm{\\theta}}_{2}^{l}\\right)\\boldsymbol{x}_{1,i}^{l}={\\bm{\\theta}}_{1}%\n^{l}\\boldsymbol{x}_{1,i}^{l}+\\Delta{\\bm{\\theta}}_{2}^{l}\\boldsym", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "69", "text": "bol{x}_{1,i}^{l}={\\bm{\\theta}}_{1}%\n^{l}\\boldsymbol{x}_{1,i}^{l}+\\Delta{\\bm{\\theta}}_{2}^{l}\\boldsymbol{x}_{1,i}^{%\nl}={\\bm{\\theta}}_{1}^{l}\\boldsymbol{x}_{1,i}^{l}.\nbold_italic_θ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT bold_italic_x start_POSTSUBSCRIPT 1 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT = ( bold_italic_θ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT + roman_Δ bold_italic_θ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT ) bold_italic_x start_POSTSUBSCRIPT 1 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "70", "text": "UPERSCRIPT ) bold_italic_x start_POSTSUBSCRIPT 1 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT = bold_italic_θ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT bold_italic_x start_POSTSUBSCRIPT 1 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT + roman_Δ bold_italic_θ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT bold_italic_x start_POSTSUBSCRIPT 1 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT = bold_italic_θ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT bold_itali", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "71", "text": "tart_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT bold_italic_x start_POSTSUBSCRIPT 1 , italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT .\n\n(3)\n\nIn Appendix \nA.1\n, we discuss in detail the respective advantages and disadvantages of gradient projection in feature space and gradient space, and how to choose them.\n\nBayesian Method\n\nBayesian approaches offer effective strategies to mitigate forgetting by incorporating uncertainty estimation and regularization techniques, thereby enhancing the adaptability of the learning process. Bayesian methods can be classified into three categories: (1) constrain the update of weight parame", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "72", "text": " Bayesian methods can be classified into three categories: (1) constrain the update of weight parameter distributions; (2) constrain the update in function space; and (3) dynamically grow the CL model architecture in an adaptive and Bayesian manner.\nSpecifically,\n(1) \nWeight Space Regularization:\n These methods model the parameter update uncertainty and enforce the model parameter (weight space) distribution when learning the new task is close to that of all the previously learned tasks, including \n[\n68\n, \n69\n, \n70\n, \n71\n, \n72\n, \n73\n]\n.\n(2) \nFunction Space Regularization:\n Different from weight space regularization which constrains the weight update, the function space regularization regulat", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "73", "text": "t space regularization which constrains the weight update, the function space regularization regulates the CL function update in the function space.\nThey achieve this goal by enforcing the posterior distribution over the function space \n[\n74\n]\n, constraining neural network predictions \n[\n75\n]\n, modeling the cross-task covariances \n[\n76\n]\n or sequential function-space variational inference \n[\n77\n]\n.\n(3) \nBayesian Architecture Expansion:\n Bayesian architecture growing methods employ a probabilistic and Bayesian approach to dynamically expand the CL model. This probabilistic framework facilitates the flexible and principled expansion of the model’s architecture, allowing it to accommodate incre", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "74", "text": " the flexible and principled expansion of the model’s architecture, allowing it to accommodate increasing complexity and variability in the learning process, including \n[\n78\n, \n79\n]\n.\n\nIn Appendix \nA.1\n, we discuss the differences and connections between weight space regularity and function space regularity in detail.\n\n2.1.2 \nTask-free CL\n\nTask-free CL assumes that the learning system does not have access to any explicit task information. Unlike the task-aware CL setting, where a sequence of tasks is defined, task-free CL aims to perform adaptation without explicit task boundaries.\nThe system needs to adapt and generalize its knowledge over time, continually updating its model or representat", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "75", "text": "needs to adapt and generalize its knowledge over time, continually updating its model or representation to accommodate new information while retaining previously learned knowledge.\nExisting approaches for task-free CL can be categorized into two classes: memory-based methods and network expansion-based methods.\n\nMemory-based method\n\nMemory-based methods \n[\n21\n, \n24\n, \n80\n, \n16\n]\n involve storing a small subset of previous data and replaying them alongside new mini-batch data. MIR \n[\n24\n]\n selects and replays samples that are most prone to interference. This selective replay aims to prioritize samples that are most relevant for retaining previously learned knowledge. Building upon MIR, GEN-MI", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "76", "text": "samples that are most relevant for retaining previously learned knowledge. Building upon MIR, GEN-MIR \n[\n24\n]\n incorporates generative models to synthesize memory examples during replay. GSS \n[\n21\n]\n focuses on storing diverse examples. GMED \n[\n81\n]\n, proposes a method for editing the memory examples to promote forgetting and discourage memorization. While GMED focuses on editing memory examples, Wang et al. \n[\n82\n]\n propose a Distributionally Robust Optimization framework that considers population- and distribution-level evolution to address memory overfitting.\n\nExpansion-based method\n\nIn architecture expansion-based methods, several approaches have been proposed to address the forgetting i", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "77", "text": "hitecture expansion-based methods, several approaches have been proposed to address the forgetting issue and facilitate continual adaptation.\nCN-DPM \n[\n83\n]\n introduces a method that expands the network structure based on the Dirichlet process mixture model.\nThis approach allows for the automatic expansion of the network to accommodate new data distributions or concepts while preserving previously learned knowledge. VariGrow \n[\n84\n]\n proposes a variational architecture growing method based on Bayesian novelty to identify novel information and dynamically expand the network architecture to accommodate new knowledge. ODDL \n[\n85\n]\n proposes a dynamical architecture expansion method based on est", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "78", "text": "mmodate new knowledge. ODDL \n[\n85\n]\n proposes a dynamical architecture expansion method based on estimating the discrepancy between the probabilistic representation of the memory buffer data and the accumulated knowledge.\n\n2.2 \nOnline CL\n\n2.2.1 \nApproaches for Online CL\n\nIn online CL, the learner is only allowed to process the data for each task once \n[\n5\n]\n. Existing works addressing forgetting in online CL are mainly based on \nrehearsal replay\n \n[\n24\n, \n21\n, \n86\n, \n87\n, \n88\n]\n.\nMIR \n[\n24\n]\n suggests replaying the samples that exhibit the maximum increase in loss. OCS \n[\n89\n]\n proposes to select samples with high affinity for old tasks.\nDVC \n[\n90\n]\n introduces a technique that involves sele", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "79", "text": "ect samples with high affinity for old tasks.\nDVC \n[\n90\n]\n introduces a technique that involves selecting samples whose gradients are most interfered with new incoming samples to store in memory buffer.\nASER \n[\n86\n]\n introduces an adversarial Shapley value method to score memory data samples based on their contribution to forgetting\nLa-MAML \n[\n91\n]\n utilizes a meta-learning algorithm to tackle online CL by leveraging a small episodic memory.\nPOCL \n[\n88\n]\n reformulates replay-based online CL into a hierarchical gradient aggregation framework and enhances past task performance while maintaining current task performance using Pareto optimization.\nIn addition, some studies have proposed \nregular", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "80", "text": "current task performance using Pareto optimization.\nIn addition, some studies have proposed \nregularization-based strategies\n to prevent forgetting \n[\n92\n, \n93\n]\n.\n\n2.2.2 \nImbalanced Class Issue in Online CL\n\nThe presence of imbalanced data streams in online CL has drawn significant attention, primarily due to its prevalence in real-world application scenarios \n[\n94\n, \n95\n, \n96\n, \n97\n]\n. Addressing class imbalance can be approached through two main strategies: (1) learning a model that effectively balances the learning of both old and new classes during training, or (2) employing post-processing techniques to calibrate the biases inherent in the model.\n\nBalance Learning Between New and Old C", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "81", "text": "ng techniques to calibrate the biases inherent in the model.\n\nBalance Learning Between New and Old Classes\n\nBalancing in the training phase involves heuristically selecting a balanced memory to tune the model \n[\n94\n, \n95\n, \n98\n, \n99\n]\n. Chrysakis et al. \n[\n98\n]\n propose class-balancing reservoir sampling (CBRS) to tackle this issue. PRS \n[\n99\n]\n suggests a partitioning reservoir sampling strategy to address this issue. Kim et al. \n[\n100\n]\n introduces a stochastic information-theoretic reservoir sampler to select memory points from the imbalanced data stream. E2E \n[\n94\n]\n proposes to alleviate the imbalance problem by adopting a balanced fine-tuning strategy at the end of each incremental sta", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "82", "text": "the imbalance problem by adopting a balanced fine-tuning strategy at the end of each incremental stage. GDumb \n[\n95\n]\n found that the downsampling strategy can well solve the problem of imbalance between old and new classes.\n\nPost-Processing Calibration Techniques\n\nPost-processing calibration methods perform bias calibration on the classifier during inference phase \n[\n96\n, \n101\n, \n102\n]\n. BiC \n[\n96\n]\n introduces a two-stage training where they perform the main training in the first stage, followed by a linear transformation to mitigate bias in the second stage. WA \n[\n102\n]\n reduces the imbalance between old and new classes by aligning the model logits outputs on the old and new classes.\nOBC ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "83", "text": "ce between old and new classes by aligning the model logits outputs on the old and new classes.\nOBC \n[\n103\n]\n provides both theoretical and empirical explanations of how replay can introduce a bias towards the most recently observed data stream. They modify the model’s output layer, aiming to mitigate the online bias.\n\n2.3 \nSemi-supervised, Few-shot and Unsupervised CL\n\n2.3.1 \nSemi-supervised CL\n\nSemi-supervised CL is an extension of traditional CL that allows each task to incorporate unlabeled data as well.\nExisting works mainly include generative replay \n[\n104\n, \n105\n]\n and distillation \n[\n58\n, \n106\n]\n to avoid forgetting. Specifically,\nORDisCo \n[\n105\n]\n maintains a relatively constant-siz", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "84", "text": "8\n, \n106\n]\n to avoid forgetting. Specifically,\nORDisCo \n[\n105\n]\n maintains a relatively constant-sized network, and it simultaneously trains a classifier and a conditional GAN, and learns the classifier by replaying data sampled from the GAN in an online fashion. SDSL \n[\n104\n]\n is also based on the generation-replay framework. GD \n[\n58\n]\n and DistillMatch \n[\n106\n]\n are distillation-based approaches. DistillMatch performs knowledge distillation by assigning pseudo-labels and data augmentation to the unlabeled data. In particular, DietCL \n[\n107\n]\n explores semi-supervised CL scenarios with sparse labeled data and limited computational budget.\n\n2.3.2 \nFew-shot CL\n\nFew-shot CL refers to the scen", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "85", "text": "e labeled data and limited computational budget.\n\n2.3.2 \nFew-shot CL\n\nFew-shot CL refers to the scenario where a model needs to learn new tasks with only a limited number of labeled examples per task while retaining knowledge from previously encountered tasks. The challenge lies in effectively leveraging the limited labeled data and previously learned knowledge to adapt to new tasks while avoiding forgetting.\n\nCompared to traditional CL, few-shot CL faces the challenge of overfitting due to the limited number of examples available per task \n[\n108\n, \n109\n]\n. To tackle the forgetting problem in few-shot CL, existing approaches employ various techniques, including metric learning, meta-learning", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "86", "text": "few-shot CL, existing approaches employ various techniques, including metric learning, meta-learning, and parameter regularization. Due to limited pages, we provide details of these methods in Appendix. \nA.2\n.\nBelow, we briefly explain each method:\n(1) \nMetric Learning-Based:\n These methods perform classification by class prototypes. To avoid forgetting, the prototype of the new class should be separable from the old class \n[\n110\n, \n111\n, \n112\n]\n, and the prototype of the old class should not change drastically during the adjustment process of the new class \n[\n112\n, \n108\n]\n.\n(2) \nMeta-Learning-Based:\n These methods simulate the inference phase during training so that CL models can quickly ad", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "87", "text": "-Based:\n These methods simulate the inference phase during training so that CL models can quickly adapt to unseen new classes to solve few-shot CL. For example, LIMIT \n[\n113\n]\n and MetaFSCIL \n[\n114\n]\n split the base task into multiple ’fake’-incremental tasks, so that the model has the learning ability of few-shot CL tasks. By reducing the loss associated with the meta-objective, they minimize forgetting of the old tasks.\n(3) \nParameter Regularization-Based:\n These methods employ various strategies to address the forgetting problem by penalizing parameter updates that are important for old tasks \n[\n115\n, \n116\n]\n.\n\n2.3.3 \nUnsupervised CL\n\nUnsupervised CL \n[\n117\n, \n118\n]\n is a rapidly growing ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "88", "text": "ks \n[\n115\n, \n116\n]\n.\n\n2.3.3 \nUnsupervised CL\n\nUnsupervised CL \n[\n117\n, \n118\n]\n is a rapidly growing research area that emphasizes learning from unlabeled data alone. Unlike traditional supervised CL relying on labeled data, unsupervised CL explores techniques that enable learning and adaptation using only unlabeled data.\n\nExisting unsupervised CL methods mainly rely on \nrepresentation-based contrastive learning\n techniques \n[\n117\n, \n119\n, \n118\n, \n120\n]\n.\nCURL \n[\n117\n]\n is the first offline continual\nunsupervised representation learning framework with unknown task labels and boundaries. Co2l \n[\n119\n]\n finds that self-supervised loss is generally more robust to forgetting than cross-entropy lo", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "89", "text": "\n119\n]\n finds that self-supervised loss is generally more robust to forgetting than cross-entropy loss in CL.\nLUMP \n[\n118\n]\n observes that unsupervised CL models have a flatter loss landscape than supervised CL models, and additionally, it performs Mixup \n[\n121\n]\n between old task samples and new task samples to reduce forgetting.\nProb \n[\n120\n]\n revisits the phenomenon of representational forgetting in both supervised and unsupervised CL settings, and shows that using observed accuracy to measure forgetting is a misleading metric because a low model accuracy on old tasks does not necessarily indicate significant changes in the learned representations. This discrepancy suggests that accuracy ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "90", "text": "ndicate significant changes in the learned representations. This discrepancy suggests that accuracy alone is not a reliable indicator of the extent of forgetting in unsupervised CL.\n\nSuitable metric for unsupervised CL\n: Following \n[\n118\n]\n and centered kernel alignment (CKA) \n[\n122\n]\n, we measure the similarity between the representations obtained using the parameters learned at the end of task \nt\n𝑡\nt\nitalic_t\n (i.e., \n𝜽\nt\nsubscript\n𝜽\n𝑡\n{\\bm{\\theta}}_{t}\nbold_italic_θ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n) and those obtained using the parameters learned at the end of the last task \nT\n𝑇\nT\nitalic_T\n (i.e., \n𝜽\nT\nsubscript\n𝜽\n𝑇\n{\\bm{\\theta}}_{T}\nbold_italic_θ start_POSTSUBSCRIPT italic", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "91", "text": "T\n𝑇\nT\nitalic_T\n (i.e., \n𝜽\nT\nsubscript\n𝜽\n𝑇\n{\\bm{\\theta}}_{T}\nbold_italic_θ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT\n) to evaluate representation forgetting. Intuitively, a higher similarity indicates less forgetting of previous data distributions. Specifically, the similarity is calculated using test data from task \nt\n𝑡\nt\nitalic_t\n, as formulated below:\n\nsim\n⁢\n(\n𝜽\nt\n,\n𝜽\nT\n;\nX\n)\n=\nHSIC\n⁢\n(\nA\n,\nB\n)\nHSIC\n⁢\n(\nA\n,\nA\n)\n⁢\nHSIC\n⁢\n(\nB\n,\nB\n)\n,\nsim\nsubscript\n𝜽\n𝑡\nsubscript\n𝜽\n𝑇\n𝑋\nHSIC\n𝐴\n𝐵\nHSIC\n𝐴\n𝐴\nHSIC\n𝐵\n𝐵\n\\centering\\small\\text{sim}\\left({\\bm{\\theta}}_{t},{\\bm{\\theta}}_{T};X\\right)=%\n\\frac{\\text{HSIC}(A,B)}{\\sqrt{\\text{HSIC}(A,A)\\text{HSIC}(B,B)}},\\@add@centering\nsim ( bold_italic_θ start_POSTSUBSCR", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "92", "text": "(A,B)}{\\sqrt{\\text{HSIC}(A,A)\\text{HSIC}(B,B)}},\\@add@centering\nsim ( bold_italic_θ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_italic_θ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ; italic_X ) = divide start_ARG HSIC ( italic_A , italic_B ) end_ARG start_ARG square-root start_ARG HSIC ( italic_A , italic_A ) HSIC ( italic_B , italic_B ) end_ARG end_ARG ,\n\n(4)\n\nwhere HSIC denotes Hilbert-Schmidt Independence Criterion, as defined in \n[\n122\n]\n. where \n(\nA\n)\ni\n,\nj\n=\na\n⁢\n(\n𝒛\ni\n,\n𝒛\nj\n)\nsubscript\n𝐴\n𝑖\n𝑗\n𝑎\nsubscript\n𝒛\n𝑖\nsubscript\n𝒛\n𝑗\n(A)_{i,j}=a({\\bm{z}}_{i},{\\bm{z}}_{j})\n( italic_A ) start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT = italic_a ( bold_italic_z start_POSTSUBSCRI", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "93", "text": "art_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT = italic_a ( bold_italic_z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_z start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT )\n, \na\n(\n,\n)\na(,)\nitalic_a ( , )\n denotes a kernel function. \n(\nA\n)\ni\n,\nj\nsubscript\n𝐴\n𝑖\n𝑗\n(A)_{i,j}\n( italic_A ) start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT\n denotes the element in \ni\n𝑖\ni\nitalic_i\n-th row and \nj\n𝑗\nj\nitalic_j\n-th column of matrix \nA\n𝐴\nA\nitalic_A\n. \n(\nB\n)\ni\n,\nj\n=\nb\n⁢\n(\n𝒖\ni\n,\n𝒖\nj\n)\nsubscript\n𝐵\n𝑖\n𝑗\n𝑏\nsubscript\n𝒖\n𝑖\nsubscript\n𝒖\n𝑗\n(B)_{i,j}=b({\\bm{u}}_{i},{\\bm{u}}_{j})\n( italic_B ) start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT = italic_b ( bold_italic_u start_POSTSUB", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "94", "text": ") start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT = italic_b ( bold_italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_italic_u start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT )\n, where \nb\n(\n,\n)\nb(,)\nitalic_b ( , )\n denotes a kernel function.\n\nX\n𝑋\nX\nitalic_X\n represents the test data of task \nt\n𝑡\nt\nitalic_t\n. \n𝒛\n𝒛\n{\\bm{z}}\nbold_italic_z\n and \n𝒖\n𝒖\n{\\bm{u}}\nbold_italic_u\n are the representations w.r.t \nX\n𝑋\nX\nitalic_X\n extracted by the CL model \nf\n𝑓\nf\nitalic_f\n with weights \n𝜽\nt\nsubscript\n𝜽\n𝑡\n{\\bm{\\theta}}_{t}\nbold_italic_θ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n and \n𝜽\nT\nsubscript\n𝜽\n𝑇\n{\\bm{\\theta}}_{T}\nbold_italic_θ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT\n, ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "95", "text": "\n𝜽\nT\nsubscript\n𝜽\n𝑇\n{\\bm{\\theta}}_{T}\nbold_italic_θ start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT\n, respectively.\n\nCKA is more suitable for evaluating representation forgetting in unsupervised CL for the following reasons:\n(1)\nCKA can capture both linear and non-linear relationships between representations. Cosine similarity, on the other hand, is limited to linear relationships and measures only the angle between two vectors, ignoring more complex relationships.\n(2) CKA is invariant to isotropic scaling and orthogonal transformations.\nCosine similarity only accounts for the direction of the vectors and is not invariant to shifts in data, which can affect the similarity measurement if data u", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "96", "text": "ectors and is not invariant to shifts in data, which can affect the similarity measurement if data undergoes certain transformations.\n\n2.4 \nTheoretical Analysis\n\nThe \ntheoretical\n analysis of CL is quite a few. Pentina et al. \n[\n123\n]\n provide a generalization bound in the PAC-Bayesian framework for CL. Karakida et al. \n[\n124\n]\n conduct a theoretical analysis of the generalization performance within a solvable case of CL. They utilized a statistical mechanical analysis of kernel ridge-less regression to provide insights into the generalization capabilities in CL.\nKim et al. \n[\n125\n]\n study class-incremental learning and provides a theoretical justification for decomposing the problem into ta", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "97", "text": "ss-incremental learning and provides a theoretical justification for decomposing the problem into task-id prediction and within-task prediction.\nEvron et al. \n[\n126\n]\n theoretically study the CL on a sequence of separable linear classification tasks with binary classes. Peng et al. \n[\n127\n]\n propose Ideal Continual Learner (ICL), which unifies multiple existing well-established CL solutions, and gives the generalization bound of ICL. Zhao et al. \n[\n128\n]\n statistically analyze regularization-based CL on linear regression tasks, highlighting the impact of various regularization terms on model performance.\n\nAccording to \n[\n127\n]\n, which provides a generalization analysis for continual learner.", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "98", "text": "erformance.\n\nAccording to \n[\n127\n]\n, which provides a generalization analysis for continual learner.\nEach task optimizes the following learning objective:\n\n𝒢\nt\n:=\narg\n⁢\nmin\n𝜽\n∈\n𝚯\n⁡\nℒ\n⁢\n(\n𝜽\n,\n𝒟\nt\n)\nassign\nsubscript\n𝒢\n𝑡\nsubscript\narg\nmin\n𝜽\n𝚯\nℒ\n𝜽\nsubscript\n𝒟\n𝑡\n{\\mathcal{G}}_{t}:=\\operatorname*{arg\\,min}_{{\\bm{\\theta}}\\in{\\bm{\\Theta}}}{%\n\\mathcal{L}}({\\bm{\\theta}},{\\mathcal{D}}_{t})\ncaligraphic_G start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT := start_OPERATOR roman_arg roman_min end_OPERATOR start_POSTSUBSCRIPT bold_italic_θ ∈ bold_Θ end_POSTSUBSCRIPT caligraphic_L ( bold_italic_θ , caligraphic_D start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )\n. Let \nc\nt\n∗\n=\nmin\n𝜽\n⁡\n𝔼\n(\n𝒙\n,\ny\n)\n∼\n𝒟\nt\n⁢\nℒ\n⁢\n(\n𝜽", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "99", "text": " start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )\n. Let \nc\nt\n∗\n=\nmin\n𝜽\n⁡\n𝔼\n(\n𝒙\n,\ny\n)\n∼\n𝒟\nt\n⁢\nℒ\n⁢\n(\n𝜽\n,\n𝒙\n,\ny\n)\nsubscript\nsuperscript\n𝑐\n𝑡\nsubscript\n𝜽\nsubscript\n𝔼\nsimilar-to\n𝒙\n𝑦\nsubscript\n𝒟\n𝑡\nℒ\n𝜽\n𝒙\n𝑦\nc^{*}_{t}=\\min_{{\\bm{\\theta}}}{\\mathbb{E}}_{({\\bm{x}},y)\\sim{\\mathcal{D}}_{t}}%\n{\\mathcal{L}}({\\bm{\\theta}},{\\bm{x}},y)\nitalic_c start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = roman_min start_POSTSUBSCRIPT bold_italic_θ end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT ( bold_italic_x , italic_y ) ∼ caligraphic_D start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_L ( bold_italic_θ , bold_italic_x , italic_y )\n; \nd\n𝑑\nd\nitalic_", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "100", "text": "SCRIPT end_POSTSUBSCRIPT caligraphic_L ( bold_italic_θ , bold_italic_x , italic_y )\n; \nd\n𝑑\nd\nitalic_d\n denotes the input dimension, i.e., \n𝒙\n∈\nℝ\nd\n𝒙\nsuperscript\nℝ\n𝑑\n{\\bm{x}}\\in{\\mathbb{R}}^{d}\nbold_italic_x ∈ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT\n; \n‖\n𝜽\n‖\n2\n≤\nR\nsubscript\nnorm\n𝜽\n2\n𝑅\n||{\\bm{\\theta}}||_{2}\\leq R\n| | bold_italic_θ | | start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ≤ italic_R\n; \nI\nt\nsubscript\n𝐼\n𝑡\nI_{t}\nitalic_I start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n denotes the number of training examples for task \nt\n𝑡\nt\nitalic_t\n.\n\nAssumption 2.1\n\nAssume all tasks share a global minimizer, i.e., \n∩\nt\n=\n1\nt\n=\nN\n𝒢\nt\n≠\n∅\nsuperscript\nsubscript\n𝑡\n1\n𝑡\n𝑁\nsubscript\n𝒢\n𝑡\n\\cap_{", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "101", "text": " a global minimizer, i.e., \n∩\nt\n=\n1\nt\n=\nN\n𝒢\nt\n≠\n∅\nsuperscript\nsubscript\n𝑡\n1\n𝑡\n𝑁\nsubscript\n𝒢\n𝑡\n\\cap_{t=1}^{t=N}{\\mathcal{G}}_{t}\\neq\\emptyset\n∩ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t = italic_N end_POSTSUPERSCRIPT caligraphic_G start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ≠ ∅\n.\n\nAssumption 2.2\n\nAssume the CL loss function is \nK\n𝐾\nK\nitalic_K\n-Lipschitz, i.e., \n|\nℒ\n⁢\n(\n𝛉\n,\n𝐱\n,\ny\n)\n−\nℒ\n⁢\n(\n𝛉\n′\n,\n𝐱\n,\ny\n)\n|\n≤\nK\n⁢\n‖\n𝛉\n−\n𝛉\n′\n‖\n2\nℒ\n𝛉\n𝐱\n𝑦\nℒ\nsuperscript\n𝛉\n′\n𝐱\n𝑦\n𝐾\nsubscript\nnorm\n𝛉\nsuperscript\n𝛉\n′\n2\n\\small|{\\mathcal{L}}({\\bm{\\theta}},{\\bm{x}},y)-{\\mathcal{L}}({\\bm{\\theta}}^{%\n\\prime},{\\bm{x}},y)|\\leq K||{\\bm{\\theta}}-{\\bm{\\theta}}^{\\prime}||_{2}\n| caligraphic_", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "102", "text": "bm{\\theta}}^{%\n\\prime},{\\bm{x}},y)|\\leq K||{\\bm{\\theta}}-{\\bm{\\theta}}^{\\prime}||_{2}\n| caligraphic_L ( bold_italic_θ , bold_italic_x , italic_y ) - caligraphic_L ( bold_italic_θ start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , bold_italic_x , italic_y ) | ≤ italic_K | | bold_italic_θ - bold_italic_θ start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT | | start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT\n.\n\nThe above two assumptions ensure the following uniform convergence \n[\n129\n]\n for \nδ\n∈\n(\n0\n,\n1\n)\n𝛿\n0\n1\n\\delta\\in(0,1)\nitalic_δ ∈ ( 0 , 1 )\n:\n\n|\n∑\ni\n=\n1\ni\n=\nI\nt\nℒ\n⁢\n(\n𝜽\n,\n𝒙\ni\n,\ny\ni\n)\n−\n𝔼\n(\n𝒙\n,\ny\n)\n∼\n𝒟\nt\n⁢\nℒ\n⁢\n(\n𝜽\n,\n𝒙\n,\ny\n)\n|\n≤\nζ\n⁢\n(\nI\nt\n,\nδ\n)\nsuperscript\nsubscript\n𝑖\n1\n𝑖\nsubscript\n𝐼\n𝑡\nℒ\n𝜽\nsubscript\n𝒙\n𝑖\nsubscript", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "103", "text": "\n,\n𝒙\n,\ny\n)\n|\n≤\nζ\n⁢\n(\nI\nt\n,\nδ\n)\nsuperscript\nsubscript\n𝑖\n1\n𝑖\nsubscript\n𝐼\n𝑡\nℒ\n𝜽\nsubscript\n𝒙\n𝑖\nsubscript\n𝑦\n𝑖\nsubscript\n𝔼\nsimilar-to\n𝒙\n𝑦\nsubscript\n𝒟\n𝑡\nℒ\n𝜽\n𝒙\n𝑦\n𝜁\nsubscript\n𝐼\n𝑡\n𝛿\n\\displaystyle\\small|\\sum_{i=1}^{i=I_{t}}{\\mathcal{L}}({\\bm{\\theta}},{\\bm{x}}_{%\ni},y_{i})-{\\mathbb{E}}_{({\\bm{x}},y)\\sim{\\mathcal{D}}_{t}}{\\mathcal{L}}({\\bm{%\n\\theta}},{\\bm{x}},y)|\\leq\\zeta(I_{t},\\delta)\n| ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i = italic_I start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUPERSCRIPT caligraphic_L ( bold_italic_θ , bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) - black", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "104", "text": "CRIPT italic_i end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) - blackboard_E start_POSTSUBSCRIPT ( bold_italic_x , italic_y ) ∼ caligraphic_D start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_L ( bold_italic_θ , bold_italic_x , italic_y ) | ≤ italic_ζ ( italic_I start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_δ )\n\n(5)\n\nwhere \nζ\n⁢\n(\nI\nt\n,\nδ\n)\n=\n𝒪\n⁢\n(\nK\n⁢\nR\n⁢\nd\n⁢\nlog\n⁡\n(\nI\nt\n)\n⁢\nlog\n⁡\n(\nd\n/\nδ\n)\nI\nt\n)\n𝜁\nsubscript\n𝐼\n𝑡\n𝛿\n𝒪\n𝐾\n𝑅\n𝑑\nsubscript\n𝐼\n𝑡\n𝑑\n𝛿\nsubscript\n𝐼\n𝑡\n\\small\\zeta(I_{t},\\delta)={\\mathcal{O}}(\\frac{KR\\sqrt{d\\log(I_{t})\\log(d/%\n\\delta)}}{\\sqrt{I_{t}}})\nitalic_ζ ( italic_I start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , itali", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "105", "text": "\n\\delta)}}{\\sqrt{I_{t}}})\nitalic_ζ ( italic_I start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_δ ) = caligraphic_O ( divide start_ARG italic_K italic_R square-root start_ARG italic_d roman_log ( italic_I start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) roman_log ( italic_d / italic_δ ) end_ARG end_ARG start_ARG square-root start_ARG italic_I start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG end_ARG )\n\nTheorem 2.3\n (Generalization Error)\n\nAssume assumption \n2.1\n and \n2.2\n holds. With probability at least of \n1\n−\nδ\n1\n𝛿\n1-\\delta\n1 - italic_δ\n, there is the following generalization bound:\n\nc\nt\n∗\n≤\n𝔼\n(\n𝒙\n,\ny\n)\n∼\n𝒟\nt\n⁢\nℒ\n⁢\n(\n𝜽\n∗\n,\n𝒙\n,\ny\n)\n≤\nc\nt\n∗\n+\nζ\n⁢\n(\nI\nt\n,\nδ\n)\nsubscript\nsuperscript", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "106", "text": "nd:\n\nc\nt\n∗\n≤\n𝔼\n(\n𝒙\n,\ny\n)\n∼\n𝒟\nt\n⁢\nℒ\n⁢\n(\n𝜽\n∗\n,\n𝒙\n,\ny\n)\n≤\nc\nt\n∗\n+\nζ\n⁢\n(\nI\nt\n,\nδ\n)\nsubscript\nsuperscript\n𝑐\n𝑡\nsubscript\n𝔼\nsimilar-to\n𝒙\n𝑦\nsubscript\n𝒟\n𝑡\nℒ\nsuperscript\n𝜽\n𝒙\n𝑦\nsubscript\nsuperscript\n𝑐\n𝑡\n𝜁\nsubscript\n𝐼\n𝑡\n𝛿\n\\displaystyle\\small c^{*}_{t}\\leq{\\mathbb{E}}_{({\\bm{x}},y)\\sim{\\mathcal{D}}_{%\nt}}{\\mathcal{L}}({\\bm{\\theta}}^{*},{\\bm{x}},y)\\leq c^{*}_{t}+\\zeta(I_{t},\\delta)\nitalic_c start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ≤ blackboard_E start_POSTSUBSCRIPT ( bold_italic_x , italic_y ) ∼ caligraphic_D start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_POSTSUBSCRIPT caligraphic_L ( bold_italic_θ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT , bold_ita", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "107", "text": "d_POSTSUBSCRIPT caligraphic_L ( bold_italic_θ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT , bold_italic_x , italic_y ) ≤ italic_c start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_ζ ( italic_I start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_δ )\n\n(6)\n\nwhere \n𝛉\n∗\nsuperscript\n𝛉\n{\\bm{\\theta}}^{*}\nbold_italic_θ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT\n denotes the optimal global CL model parameters after completing the last task.\n\n4 \nForgetting in Domain Adaptation\n\nThe objective of domain adaptation is to transfer knowledge from a source domain to a target domain. A domain represents the joint distribution of the input space \n𝒳\n𝒳\n{\\mat", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "108", "text": " domain to a target domain. A domain represents the joint distribution of the input space \n𝒳\n𝒳\n{\\mathcal{X}}\ncaligraphic_X\n and the output space \n𝒴\n𝒴\n{\\mathcal{Y}}\ncaligraphic_Y\n. Specifically, the source domain is defined as \n𝒫\nS\n⁢\n(\n𝒙\n,\ny\n)\nsuperscript\n𝒫\n𝑆\n𝒙\n𝑦\n{\\mathcal{P}}^{S}({\\bm{x}},y)\ncaligraphic_P start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ( bold_italic_x , italic_y )\n, where \n𝒙\n𝒙\n{\\bm{x}}\nbold_italic_x\n belongs to the input space \n𝒳\nS\nsuperscript\n𝒳\n𝑆\n{\\mathcal{X}}^{S}\ncaligraphic_X start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT\n and \ny\n𝑦\ny\nitalic_y\n belongs to the output space \n𝒴\nS\nsuperscript\n𝒴\n𝑆\n{\\mathcal{Y}}^{S}\ncaligraphic_Y start_POSTSUPERSCRIPT italic_S end_POSTSUP", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "109", "text": "pace \n𝒴\nS\nsuperscript\n𝒴\n𝑆\n{\\mathcal{Y}}^{S}\ncaligraphic_Y start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT\n. Similarly, the target domain is defined as \n𝒫\nT\n⁢\n(\n𝒙\n,\ny\n)\nsuperscript\n𝒫\n𝑇\n𝒙\n𝑦\n{\\mathcal{P}}^{T}({\\bm{x}},y)\ncaligraphic_P start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( bold_italic_x , italic_y )\n, where \n𝒙\n𝒙\n{\\bm{x}}\nbold_italic_x\n belongs to the input space \n𝒳\nT\nsuperscript\n𝒳\n𝑇\n{\\mathcal{X}}^{T}\ncaligraphic_X start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT\n and \ny\n𝑦\ny\nitalic_y\n belongs to the output space \n𝒴\nT\nsuperscript\n𝒴\n𝑇\n{\\mathcal{Y}}^{T}\ncaligraphic_Y start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT\n.\n\nIn continual domain adaptation (CDA) \n[\n164\n]\n, the focus is", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "110", "text": "RSCRIPT italic_T end_POSTSUPERSCRIPT\n.\n\nIn continual domain adaptation (CDA) \n[\n164\n]\n, the focus is primarily on the covariate shift setting. Covariate shift refers to a situation where the distribution of input data, \n𝒳\n𝒳\n{\\mathcal{X}}\ncaligraphic_X\n, differs between the source and target domains, while the conditional distribution of the output, \n𝒴\n𝒴\n{\\mathcal{Y}}\ncaligraphic_Y\n, remains the same. This setting assumes that the relationship between inputs and outputs remains consistent across domains, but the distributions of the input data vary. This is formally defined as the following:\n\n𝒫\nS\n⁢\n(\nX\n=\n𝒙\n)\n≠\n𝒫\nT\n⁢\n(\nX\n=\n𝒙\n)\n,\n𝒫\nS\n⁢\n(\ny\n|\nX\n=\n𝒙\n)\n=\n𝒫\nT\n⁢\n(\ny\n|\nX\n=\n𝒙\n)\n.\nformulae-sequence\nsup", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "111", "text": "\nS\n⁢\n(\nX\n=\n𝒙\n)\n≠\n𝒫\nT\n⁢\n(\nX\n=\n𝒙\n)\n,\n𝒫\nS\n⁢\n(\ny\n|\nX\n=\n𝒙\n)\n=\n𝒫\nT\n⁢\n(\ny\n|\nX\n=\n𝒙\n)\n.\nformulae-sequence\nsuperscript\n𝒫\n𝑆\n𝑋\n𝒙\nsuperscript\n𝒫\n𝑇\n𝑋\n𝒙\nsuperscript\n𝒫\n𝑆\nconditional\n𝑦\n𝑋\n𝒙\nsuperscript\n𝒫\n𝑇\nconditional\n𝑦\n𝑋\n𝒙\n\\small{\\mathcal{P}}^{S}(X={\\bm{x}})\\neq{\\mathcal{P}}^{T}(X={\\bm{x}}),{\\mathcal%\n{P}}^{S}(y|X={\\bm{x}})={\\mathcal{P}}^{T}(y|X={\\bm{x}}).\\!\\!\ncaligraphic_P start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ( italic_X = bold_italic_x ) ≠ caligraphic_P start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( italic_X = bold_italic_x ) , caligraphic_P start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ( italic_y | italic_X = bold_italic_x ) = caligraphic_P start_POSTSUPERSCRIPT italic_T end_POSTSUP", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "112", "text": "T ( italic_y | italic_X = bold_italic_x ) = caligraphic_P start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( italic_y | italic_X = bold_italic_x ) .\n\n(7)\n\nCDA and traditional CL have distinct characteristics and goals.\nOn the one hand, CDA differs from traditional CL in terms of the availability of source domain data for transferring knowledge across the target domain sequence. In CDA, the source domain data is accessible, and the objective is to adapt the model from the source domain to the target domain, leveraging the available source domain data. However, the target domain may only provide unlabeled data, requiring the model to adapt to the new domain without explicit supervision.\nOn t", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "113", "text": "de unlabeled data, requiring the model to adapt to the new domain without explicit supervision.\nOn the other hand, traditional CL aims to learn and adapt the model to a sequence of tasks without accessing previous task-specific labeled data. Labeled data is typically provided for each task in traditional CL.\n\nProblem Setup:\n\nSuppose we have a pre-trained model \nf\n𝜽\nsubscript\n𝑓\n𝜽\nf_{{\\bm{\\theta}}}\nitalic_f start_POSTSUBSCRIPT bold_italic_θ end_POSTSUBSCRIPT\n that has been trained on a set of source domain data \n𝒫\nS\n⁢\n(\n𝒙\n,\ny\n)\nsuperscript\n𝒫\n𝑆\n𝒙\n𝑦\n{\\mathcal{P}}^{S}({\\bm{x}},y)\ncaligraphic_P start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ( bold_italic_x , italic_y )\n, where \n𝒙\n𝒙\n{\\bm{x}}\nbo", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "114", "text": "t_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ( bold_italic_x , italic_y )\n, where \n𝒙\n𝒙\n{\\bm{x}}\nbold_italic_x\n belongs to the source domain input space \n𝒳\nS\nsuperscript\n𝒳\n𝑆\n{\\mathcal{X}}^{S}\ncaligraphic_X start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT\n and \ny\n𝑦\ny\nitalic_y\n belongs to the source domain label space \n𝒴\nS\nsuperscript\n𝒴\n𝑆\n{\\mathcal{Y}}^{S}\ncaligraphic_Y start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT\n. Additionally, we have a sequence of evolving target distributions \n𝒫\nt\nT\n⁢\n(\n𝒙\n,\ny\n)\nsuperscript\nsubscript\n𝒫\n𝑡\n𝑇\n𝒙\n𝑦\n{\\mathcal{P}}_{t}^{T}({\\bm{x}},y)\ncaligraphic_P start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( bold_ita", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "115", "text": "STSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( bold_italic_x , italic_y )\n, where \n𝒙\n𝒙\n{\\bm{x}}\nbold_italic_x\n belongs to the input space \n𝒳\nt\nT\nsubscript\nsuperscript\n𝒳\n𝑇\n𝑡\n{\\mathcal{X}}^{T}_{t}\ncaligraphic_X start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n of the target domain \nt\n𝑡\nt\nitalic_t\n. \ny\n𝑦\ny\nitalic_y\n belongs to the label space \n𝒴\nt\nT\nsubscript\nsuperscript\n𝒴\n𝑇\n𝑡\n{\\mathcal{Y}}^{T}_{t}\ncaligraphic_Y start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n of the target domain \nt\n𝑡\nt\nitalic_t\n. \nt\n𝑡\nt\nitalic_t\n represents the domain index ranging fr", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "116", "text": "RIPT\n of the target domain \nt\n𝑡\nt\nitalic_t\n. \nt\n𝑡\nt\nitalic_t\n represents the domain index ranging from 1 to \nN\n𝑁\nN\nitalic_N\n.\nThe objective of CDA, as proposed in \n[\n164\n]\n, is to train \nf\n𝜽\nsubscript\n𝑓\n𝜽\nf_{{\\bm{\\theta}}}\nitalic_f start_POSTSUBSCRIPT bold_italic_θ end_POSTSUBSCRIPT\n in such a way that it performs well on all the domains \n𝒫\nt\nT\n⁢\n(\n𝒙\n,\ny\n)\nsuperscript\nsubscript\n𝒫\n𝑡\n𝑇\n𝒙\n𝑦\n{\\mathcal{P}}_{t}^{T}({\\bm{x}},y)\ncaligraphic_P start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( bold_italic_x , italic_y )\n in the evolving target domain sequence, defined as follows:\n\nmin\n𝜽\n⁡\n𝔼\nt\n∈\n[\n1\n,\n…\n,\nN\n]\n⁢\n𝔼\n𝒙\nT\n∼\nP\nt\nT\n,\n𝒙\nS\n∼\nP\nS\n⁢\nℒ\n⁢\n(\nf\n𝜽\n⁢\n(\n", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "117", "text": "uence, defined as follows:\n\nmin\n𝜽\n⁡\n𝔼\nt\n∈\n[\n1\n,\n…\n,\nN\n]\n⁢\n𝔼\n𝒙\nT\n∼\nP\nt\nT\n,\n𝒙\nS\n∼\nP\nS\n⁢\nℒ\n⁢\n(\nf\n𝜽\n⁢\n(\n𝒙\nT\n)\n,\nf\n𝜽\n⁢\n(\n𝒙\nS\n)\n)\n.\nsubscript\n𝜽\nsubscript\n𝔼\n𝑡\n1\n…\n𝑁\nsubscript\n𝔼\nformulae-sequence\nsimilar-to\nsuperscript\n𝒙\n𝑇\nsubscript\nsuperscript\n𝑃\n𝑇\n𝑡\nsimilar-to\nsuperscript\n𝒙\n𝑆\nsuperscript\n𝑃\n𝑆\nℒ\nsubscript\n𝑓\n𝜽\nsuperscript\n𝒙\n𝑇\nsubscript\n𝑓\n𝜽\nsuperscript\n𝒙\n𝑆\n\\small\\min_{{\\bm{\\theta}}}\\mathbb{E}_{t\\in[1,\\ldots,N]}\\mathbb{E}_{{\\bm{x}}^{T%\n}\\sim P^{T}_{t},{\\bm{x}}^{S}\\sim P^{S}}\\mathcal{L}\\left(f_{{\\bm{\\theta}}}({\\bm%\n{x}}^{T}),f_{{\\bm{\\theta}}}({\\bm{x}}^{S})\\right).\nroman_min start_POSTSUBSCRIPT bold_italic_θ end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT italic_t ∈ [ 1 , … , italic_N ] end_POSTSUBSCRI", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "118", "text": "θ end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT italic_t ∈ [ 1 , … , italic_N ] end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT bold_italic_x start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ∼ italic_P start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , bold_italic_x start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ∼ italic_P start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT end_POSTSUBSCRIPT caligraphic_L ( italic_f start_POSTSUBSCRIPT bold_italic_θ end_POSTSUBSCRIPT ( bold_italic_x start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ) , italic_f start_POSTSUBSCRIPT bold_italic_θ end_POSTSUBSCRIPT ( bold_italic_x start_POSTSUPERSCR", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "119", "text": " ) , italic_f start_POSTSUBSCRIPT bold_italic_θ end_POSTSUBSCRIPT ( bold_italic_x start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ) ) .\n\n(8)\n\nWhere \n𝔼\n𝔼\n\\mathbb{E}\nblackboard_E\n denotes expectation, \nℒ\nℒ\n\\mathcal{L}\ncaligraphic_L\n denotes the KL divergence if \nf\n𝜽\n⁢\n(\n𝒙\nT\n)\n,\nf\n𝜽\n⁢\n(\n𝒙\nS\n)\nsubscript\n𝑓\n𝜽\nsuperscript\n𝒙\n𝑇\nsubscript\n𝑓\n𝜽\nsuperscript\n𝒙\n𝑆\nf_{{\\bm{\\theta}}}({\\bm{x}}^{T}),f_{{\\bm{\\theta}}}({\\bm{x}}^{S})\nitalic_f start_POSTSUBSCRIPT bold_italic_θ end_POSTSUBSCRIPT ( bold_italic_x start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ) , italic_f start_POSTSUBSCRIPT bold_italic_θ end_POSTSUBSCRIPT ( bold_italic_x start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT )\n represent the model", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "120", "text": "TSUBSCRIPT ( bold_italic_x start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT )\n represent the model output logits or \nl\n1\n,\nl\n2\nsubscript\n𝑙\n1\nsubscript\n𝑙\n2\nl_{1},l_{2}\nitalic_l start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_l start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT\n distance function if they denote the feature representations.\n\nWhen learning new target domains, their data distributions differ from that of the source domain. As a result, adapting the model to new domains can lead to forgetting the knowledge acquired from previous domains. Various methods have been developed to tackle the forgetting issue.\n\nWhen the source domain data is available, most of the works avoid forgetting by repl", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "121", "text": "getting issue.\n\nWhen the source domain data is available, most of the works avoid forgetting by replaying the source domain data \n[\n165\n, \n166\n, \n167\n]\n, and a few works are based on regularization \n[\n168\n]\n, or meta-learning \n[\n169\n]\n.\nFirst, CUA \n[\n165\n]\n, addresses forgetting by randomly selecting samples from previous domains and stores them in a memory buffer. UCL-GV \n[\n170\n]\n utilizes a First-In, First-Out (FIFO) buffer to replay episodic memory.\nAuCID \n[\n166\n]\n tackles CDA by consolidating the learned internal distribution. It achieves this by storing a fixed number of confident samples for each class per domain, which are later replayed during the adaptation process.\nThen, GRCL \n[\n16", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "122", "text": " for each class per domain, which are later replayed during the adaptation process.\nThen, GRCL \n[\n168\n]\n utilizes the gradient direction of samples from the previous domain as a \nregularization\n term. This constraint ensures that the model can be updated with new target domain data without negatively affecting the performance of the previous domains.\nFinally, Meta-DR \n[\n169\n]\n proposes a \nmeta-learning\n and domain randomization approach to mitigate forgetting and retain knowledge from previous domains during CDA.\n\nRecently, few works have focused on \nsource-free\n approaches \n[\n171\n]\n that protect the source domain data privacy, which is often inaccessible in many scenarios \n[\n172\n, \n173\n]\n. ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "123", "text": "ect the source domain data privacy, which is often inaccessible in many scenarios \n[\n172\n, \n173\n]\n. CoSDA \n[\n172\n]\n introduces a knowledge distillation method that employs a dual-speed teacher-student structure. The slow-updating teacher preserves the long-term knowledge of previous domains, while the fast-updating student quickly adapts to the target domain. C-SUDA \n[\n173\n]\n synthesizes source-style images to prevent forgetting.\n\n5 \nForgetting in Test Time Adaptation\n\nTest time adaptation (TTA) refers to the process of adapting a pre-trained model to unlabeled test data during inference or testing \n[\n174\n, \n175\n, \n176\n, \n177\n, \n178\n]\n. Unlike domain adaptation, TTA occurs during the deploym", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "124", "text": "sting \n[\n174\n, \n175\n, \n176\n, \n177\n, \n178\n]\n. Unlike domain adaptation, TTA occurs during the deployment phase rather than during the training phase.\nIn traditional machine learning scenarios, during testing, it is typically assumed that the test data \n𝒟\nt\n⁢\ne\n⁢\ns\n⁢\nt\nsubscript\n𝒟\n𝑡\n𝑒\n𝑠\n𝑡\n{\\mathcal{D}}_{test}\ncaligraphic_D start_POSTSUBSCRIPT italic_t italic_e italic_s italic_t end_POSTSUBSCRIPT\n follows the same distribution as the training data. However, in real-world applications, it is common for the test data distribution to deviate from the training data distribution.\nTo address the distribution shift, TTA adapts the pre-trained model on the unlabeled testing data \n𝒙\n𝒙\n{\\bm{x}}\nbold_ital", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "125", "text": "bution shift, TTA adapts the pre-trained model on the unlabeled testing data \n𝒙\n𝒙\n{\\bm{x}}\nbold_italic_x\n using an unsupervised adaptation loss. This adaptation aims to minimize the loss function \nℒ\n⁢\n(\n𝒙\n,\n𝜽\n)\nℒ\n𝒙\n𝜽\n{\\mathcal{L}}({\\bm{x}},{\\bm{\\theta}})\ncaligraphic_L ( bold_italic_x , bold_italic_θ )\n with respect to the parameters \n𝜽\n𝜽\n{\\bm{\\theta}}\nbold_italic_θ\n. It is important to note that \n𝒙\n𝒙\n{\\bm{x}}\nbold_italic_x\n is sampled from the testing dataset, \n𝒟\nt\n⁢\ne\n⁢\ns\n⁢\nt\nsubscript\n𝒟\n𝑡\n𝑒\n𝑠\n𝑡\n{\\mathcal{D}}_{test}\ncaligraphic_D start_POSTSUBSCRIPT italic_t italic_e italic_s italic_t end_POSTSUBSCRIPT\n.\nSubsequently, the adapted model utilizes the updated parameters to make predictions for", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "126", "text": "TSUBSCRIPT\n.\nSubsequently, the adapted model utilizes the updated parameters to make predictions for the test input \n𝒙\n𝒙\n{\\bm{x}}\nbold_italic_x\n. This allows the model to account for the distribution shift between training and testing, and hopefully improve its performance on test data.\n\nExisting Works:\n\nTent \n[\n174\n]\n minimizes the entropy of model predictions on test data, thereby improving the model’s ability to generalize to unseen examples.\nMECTA \n[\n179\n]\n proposes techniques to adapt the model during testing while optimizing memory usage, ensuring efficient and effective adaptation to the test data distribution.\nMEMO \n[\n180\n]\n applies various data augmentations to a test data point. Su", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "127", "text": "e test data distribution.\nMEMO \n[\n180\n]\n applies various data augmentations to a test data point. Subsequently, all model parameters are adapted by minimizing the entropy of the model’s output distribution across the augmented samples.\n\nWhen a pre-trained model is adapted to new unlabeled test data, the model shifts to the new data, potentially causing it to forget crucial information previously learned from the in-distribution (ID) data. This phenomenon can result in a substantial loss of knowledge and adversely affect the model’s overall performance \n[\n175\n, \n181\n]\n. To address this issue, existing approaches primarily adopt two strategies.\n\nFirstly, one approach is to replay a small porti", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "128", "text": "xisting approaches primarily adopt two strategies.\n\nFirstly, one approach is to replay a small portion of ID data during the\nadaptation process to alleviate the forgetting issue. Without loss of generality, any data selection methods mentioned in the section (memory-based methods for continual learning) can be applied. For example, one can select the sample set closest to the class center, the sample set closest to the decision boundary, or the sample set with greater diversity. RMT \n[\n182\n]\n randomly samples 1% of the ID data. AUTO \n[\n183\n]\n stores one sample per class, which is initialized from randomly selected training samples. During training, samples from the same class are replaced ac", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "129", "text": "rom randomly selected training samples. During training, samples from the same class are replaced according to a predefined rule.\n\nSecondly, one can employ a two-step process to prevent the forgetting issue. Initially, the model trained on the ID data is frozen. Subsequently, new learnable parameters are introduced to adapt the model to test data \n[\n184\n, \n185\n]\n. For instance, VDP \n[\n184\n]\n prevents forgetting by freezing the model trained on the ID data and instead learns a set of visual prompts tailored to the test data. These prompts help the model adapt effectively to out-of-distribution (OOD) data. Similarly, EcoTTA \n[\n185\n]\n freezes the pre-trained network on ID data and introduces a ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "130", "text": "(OOD) data. Similarly, EcoTTA \n[\n185\n]\n freezes the pre-trained network on ID data and introduces a lightweight meta-network to facilitate adaptation to OOD data while retaining the valuable ID data knowledge.\n\nThirdly, one can constrain the updates of important parameters to prevent forgetting in TTA. Tent \n[\n174\n]\n specifically focuses on preserving the previous knowledge by updating only the BatchNorm layer. CoTTA \n[\n181\n]\n randomly restores the weights of certain neurons to the weights that were originally trained on ID data. This restoration mechanism helps in retaining the knowledge acquired from the ID data.\nOther approaches employ techniques similar to regularization-based approaches", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "131", "text": "ired from the ID data.\nOther approaches employ techniques similar to regularization-based approaches in traditional CL. These methods penalize the updating of parameters that are deemed important to ID data during TTA \n[\n186\n, \n175\n, \n187\n]\n.\nFor instance, EATA \n[\n175\n]\n calculates the importance using the Fisher information matrix to penalize the parameters updates.\n\n7 \nForgetting in Reinforcement Learning\n\nWhile most existing CL methods primarily tackle the issue of forgetting in image classification, it is important to note that forgetting also widely occurs in reinforcement learning (RL), known as continual RL. Addressing forgetting in RL is vital for the advancement of intelligent agent", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "132", "text": "known as continual RL. Addressing forgetting in RL is vital for the advancement of intelligent agents that can continuously adapt to new tasks and environments \n[\n200\n]\n.\n\nStandard RL formulation could be defined as the following.\nWe denote \n𝒮\n𝒮\n{\\mathcal{S}}\ncaligraphic_S\n as the state space, \n𝒜\n𝒜\n{\\mathcal{A}}\ncaligraphic_A\n as the action space, and a reward function is \nr\n⁢\n(\ns\nt\n,\na\nt\n)\n:\n𝒮\n×\n𝒜\n→\nR\n:\n𝑟\nsubscript\n𝑠\n𝑡\nsubscript\n𝑎\n𝑡\n→\n𝒮\n𝒜\n𝑅\nr(s_{t},a_{t}):{\\mathcal{S}}\\times{\\mathcal{A}}\\rightarrow R\nitalic_r ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) : caligraphic_S × caligraphic_A → italic_R\n, where \nr\n⁢\n(\ns\nt\n,\na\n", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "133", "text": "RIPT italic_t end_POSTSUBSCRIPT ) : caligraphic_S × caligraphic_A → italic_R\n, where \nr\n⁢\n(\ns\nt\n,\na\nt\n)\n𝑟\nsubscript\n𝑠\n𝑡\nsubscript\n𝑎\n𝑡\nr(s_{t},a_{t})\nitalic_r ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )\n denotes the immediate reward received after taking action \na\nt\nsubscript\n𝑎\n𝑡\na_{t}\nitalic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n in state \ns\nt\nsubscript\n𝑠\n𝑡\ns_{t}\nitalic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n. At each time step \nt\n𝑡\nt\nitalic_t\n, the agent sample action from a policy function which output the optimal action or the distributions over the action space. The deterministic policy takes t", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "134", "text": "tput the optimal action or the distributions over the action space. The deterministic policy takes the current state \ns\nt\nsubscript\n𝑠\n𝑡\ns_{t}\nitalic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n as input, and outputs the optimal action \na\nt\nsubscript\n𝑎\n𝑡\na_{t}\nitalic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n that should be performed at the current state \ns\nt\nsubscript\n𝑠\n𝑡\ns_{t}\nitalic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n according to \na\nt\n=\nμ\n⁢\n(\ns\nt\n)\nsubscript\n𝑎\n𝑡\n𝜇\nsubscript\n𝑠\n𝑡\na_{t}=\\mu(s_{t})\nitalic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_μ ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )\n, where \nμ\n𝜇\n\\mu\nitalic_μ\n denotes the deter", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "135", "text": "alic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )\n, where \nμ\n𝜇\n\\mu\nitalic_μ\n denotes the deterministic policy network. A stochastic policy takes the state \ns\nt\nsubscript\n𝑠\n𝑡\ns_{t}\nitalic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n as input, outputs the optimal action distribution according to \na\nt\n∼\nπ\n⁢\n(\na\nt\n|\ns\nt\n)\nsimilar-to\nsubscript\n𝑎\n𝑡\n𝜋\nconditional\nsubscript\n𝑎\n𝑡\nsubscript\n𝑠\n𝑡\na_{t}\\sim\\pi(a_{t}|s_{t})\nitalic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∼ italic_π ( italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )\n, where \nπ\n𝜋\n\\pi\nitalic_π\n denotes the stochastic policy network. Then, the state transitio", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "136", "text": "SCRIPT )\n, where \nπ\n𝜋\n\\pi\nitalic_π\n denotes the stochastic policy network. Then, the state transition function takes the state \ns\nt\nsubscript\n𝑠\n𝑡\ns_{t}\nitalic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n and action \na\nt\nsubscript\n𝑎\n𝑡\na_{t}\nitalic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n as input and outputs the next state \ns\nt\n+\n1\nsubscript\n𝑠\n𝑡\n1\ns_{t+1}\nitalic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT\n either deterministically \ns\nt\n+\n1\n=\nf\n⁢\n(\ns\nt\n,\na\nt\n)\nsubscript\n𝑠\n𝑡\n1\n𝑓\nsubscript\n𝑠\n𝑡\nsubscript\n𝑎\n𝑡\ns_{t+1}=f(s_{t},a_{t})\nitalic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT = italic_f ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "137", "text": "_POSTSUBSCRIPT = italic_f ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )\n or stochastically \ns\nt\n+\n1\n∼\np\n⁢\n(\ns\nt\n+\n1\n|\ns\nt\n,\na\nt\n)\nsimilar-to\nsubscript\n𝑠\n𝑡\n1\n𝑝\nconditional\nsubscript\n𝑠\n𝑡\n1\nsubscript\n𝑠\n𝑡\nsubscript\n𝑎\n𝑡\ns_{t+1}\\sim p(s_{t+1}|s_{t},a_{t})\nitalic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT ∼ italic_p ( italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT | italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )\n, where \nf\n𝑓\nf\nitalic_f\n denotes the deterministic state transition function and \np\n𝑝\np\nitalic_p\n denotes the stochastic state ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "138", "text": "notes the deterministic state transition function and \np\n𝑝\np\nitalic_p\n denotes the stochastic state transition function. The goal of RL is to accumulate as much reward as possible. Following \n[\n200\n]\n, the general continual RL can be defined as:\n\nDefinition 7.1\n\n(General Continual RL): Given a state space \n𝒮\n𝒮\n{\\mathcal{S}}\ncaligraphic_S\n, action space \n𝒜\n𝒜\n{\\mathcal{A}}\ncaligraphic_A\n and observation space \n𝒪\n𝒪\n{\\mathcal{O}}\ncaligraphic_O\n. A reward function is \nr\n:\n𝒮\n×\n𝒜\n→\nR\n:\n𝑟\n→\n𝒮\n𝒜\n𝑅\nr:{\\mathcal{S}}\\times{\\mathcal{A}}\\rightarrow R\nitalic_r : caligraphic_S × caligraphic_A → italic_R\n; A state transition function is \np\n:\n𝒮\n×\n𝒜\n→\n𝒮\n:\n𝑝\n→\n𝒮\n𝒜\n𝒮\np:{\\mathcal{S}}\\times{\\mathcal{A}}\\rightarrow{", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "139", "text": "ate transition function is \np\n:\n𝒮\n×\n𝒜\n→\n𝒮\n:\n𝑝\n→\n𝒮\n𝒜\n𝒮\np:{\\mathcal{S}}\\times{\\mathcal{A}}\\rightarrow{\\mathcal{S}}\nitalic_p : caligraphic_S × caligraphic_A → caligraphic_S\n; An observation function is \nx\n:\n𝒮\n→\n𝒪\n:\n𝑥\n→\n𝒮\n𝒪\nx:{\\mathcal{S}}\\rightarrow{\\mathcal{O}}\nitalic_x : caligraphic_S → caligraphic_O\n. The general continual RL can be formulated as\n\nℳ\n⁢\n=\nd\n⁢\ne\n⁢\nf\n⁢\n⟨\n𝒮\n⁢\n(\nt\n)\n,\n𝒜\n⁢\n(\nt\n)\n,\nr\n⁢\n(\nt\n)\n,\np\n⁢\n(\nt\n)\n,\nx\n⁢\n(\nt\n)\n,\n𝒪\n⁢\n(\nt\n)\n⟩\n.\nℳ\n𝑑\n𝑒\n𝑓\n𝒮\n𝑡\n𝒜\n𝑡\n𝑟\n𝑡\n𝑝\n𝑡\n𝑥\n𝑡\n𝒪\n𝑡\n\\small{\\mathcal{M}}\\overset{def}{=}\\langle{\\mathcal{S}}(t),{\\mathcal{A}}(t),r(%\nt),p(t),x(t),{\\mathcal{O}}(t)\\rangle.\ncaligraphic_M start_OVERACCENT italic_d italic_e italic_f end_OVERACCENT start_ARG = end_ARG ⟨ caligraphic", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "140", "text": "aphic_M start_OVERACCENT italic_d italic_e italic_f end_OVERACCENT start_ARG = end_ARG ⟨ caligraphic_S ( italic_t ) , caligraphic_A ( italic_t ) , italic_r ( italic_t ) , italic_p ( italic_t ) , italic_x ( italic_t ) , caligraphic_O ( italic_t ) ⟩ .\n\n(9)\n\nDefinition \n7.1\n highlights that in continual RL, various components such as the state, action, reward, observation, and more, undergo changes over time. This emphasizes the dynamic nature of the RL process in continual settings.\n\nContinual RL approach\n. The existing continual RL methods can be categorized into four main groups: (1) \nregularization-based methods.\n These approaches employ techniques such as knowledge distillation to alleviat", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "141", "text": "zation-based methods.\n These approaches employ techniques such as knowledge distillation to alleviate forgetting \n[\n201\n]\n. Distillation can enhance experiences for training the policy or value function by offering an auxiliary target for the network to emulate. It is a widely-used technique for applying conservative updates, ensuring the agent’s learning remains stable and retains essential knowledge from previous tasks. (2) \nrehearsal-based methods.\n These methods utilize rehearsal or experience replay to mitigate forgetting \n[\n202\n]\n. Specifically, a memory buffer is employed to generate realistic samples from previous experiences. Replay techniques help reduce short-term biases in the ob", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "142", "text": "alistic samples from previous experiences. Replay techniques help reduce short-term biases in the objective function by leveraging past experiences as approximations for future situations. Therefore, replay has emerged as a highly effective approach for managing continual RL. (3) \narchitecture-based methods.\n These approaches focus on learning a shared structure, such as network modularity or composition, to facilitate continual learning \n[\n203\n]\n. CL agents need to solve problems by finding useful patterns that help them in the future. They should reuse parts of previous solutions by forming abstract concepts or skills. Humans naturally break complex tasks into smaller ones and use knowledg", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "143", "text": "abstract concepts or skills. Humans naturally break complex tasks into smaller ones and use knowledge from different timescales to plan and learn. Equipping continual RL agents with the ability to compose relevant modules from previous experiences will help them retain and transfer knowledge. (4) \nmeta-learning-based methods\n \n[\n204\n]\n. Meta-learning is an effective method that boosts the learning efficiency of CL agents. By utilizing past successes and failures, the agent learns to refine its optimization processes during continual RL. If these refinements generalize effectively to future tasks, meta-learning creates an inductive bias that enhances the agent’s sample efficiency and adaptabi", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "144", "text": "ks, meta-learning creates an inductive bias that enhances the agent’s sample efficiency and adaptability in acquiring new behaviors. This capability is crucial for achieving efficient and adaptive continual RL.\n\nAppendix B \nForgetting in Meta-Learning\n\nMeta-learning, also known as learning to learn, focuses on developing algorithms and models that can learn from previous learning experiences to improve their ability to learn new tasks or adapt to new domains more efficiently and effectively.\nIn meta-learning, the goal is to enable a learning system, often referred to as the meta-learner or the meta-model, to acquire general knowledge or \"meta-knowledge\" from a set of related learning tasks o", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "145", "text": " meta-model, to acquire general knowledge or \"meta-knowledge\" from a set of related learning tasks or domains. This meta-knowledge is then leveraged to facilitate faster learning, better generalization, and improved adaptation to new, unseen tasks or domains.\n\nFormally, let’s consider a distribution of tasks, denoted as \nP\n⁢\n(\n𝒯\n)\n𝑃\n𝒯\nP({\\mathcal{T}})\nitalic_P ( caligraphic_T )\n. For a specific task \n𝒯\nt\nsubscript\n𝒯\n𝑡\n{\\mathcal{T}}_{t}\ncaligraphic_T start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n, which consists of a training dataset \n𝒟\ntrain\nsubscript\n𝒟\ntrain\n{\\mathcal{D}}_{\\text{train}}\ncaligraphic_D start_POSTSUBSCRIPT train end_POSTSUBSCRIPT\n and a validation dataset \n𝒟\nval\nsubscript\n𝒟\nv", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "146", "text": "graphic_D start_POSTSUBSCRIPT train end_POSTSUBSCRIPT\n and a validation dataset \n𝒟\nval\nsubscript\n𝒟\nval\n{\\mathcal{D}}_{\\text{val}}\ncaligraphic_D start_POSTSUBSCRIPT val end_POSTSUBSCRIPT\n, sampled from the task distribution \nP\n⁢\n(\n𝒯\n)\n𝑃\n𝒯\nP({\\mathcal{T}})\nitalic_P ( caligraphic_T )\n.\nThe loss function for task \n𝒯\nt\nsubscript\n𝒯\n𝑡\n{\\mathcal{T}}_{t}\ncaligraphic_T start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT\n with meta-parameters \n𝜽\n𝜽\n{\\bm{\\theta}}\nbold_italic_θ\n is defined as:\n\nℒ\n⁢\n(\n𝒯\nt\n)\n=\nlog\n⁡\nP\n⁢\n(\n𝒟\nval\n|\n𝒟\ntrain\n;\n𝜽\n)\n.\nℒ\nsubscript\n𝒯\n𝑡\n𝑃\nconditional\nsubscript\n𝒟\nval\nsubscript\n𝒟\ntrain\n𝜽\n\\small{\\mathcal{L}}({\\mathcal{T}}_{t})=\\log P({\\mathcal{D}}_{\\text{val}}|{%\n\\mathcal{D}}_{\\text{train}}", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "147", "text": "all{\\mathcal{L}}({\\mathcal{T}}_{t})=\\log P({\\mathcal{D}}_{\\text{val}}|{%\n\\mathcal{D}}_{\\text{train}};{\\bm{\\theta}}).\ncaligraphic_L ( caligraphic_T start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) = roman_log italic_P ( caligraphic_D start_POSTSUBSCRIPT val end_POSTSUBSCRIPT | caligraphic_D start_POSTSUBSCRIPT train end_POSTSUBSCRIPT ; bold_italic_θ ) .\n\n(13)\n\nThe objective of meta-learning is to optimize the meta loss function, given by:\n\nmin\n𝜽\n⁡\n𝔼\n𝒯\nt\n∼\nP\n⁢\n(\n𝒯\n)\n⁢\nℒ\n⁢\n(\n𝒯\nt\n)\n.\nsubscript\n𝜽\nsubscript\n𝔼\nsimilar-to\nsubscript\n𝒯\n𝑡\n𝑃\n𝒯\nℒ\nsubscript\n𝒯\n𝑡\n\\small\\min_{{\\bm{\\theta}}}\\mathbb{E}_{{\\mathcal{T}}_{t}\\sim P({\\mathcal{T}})}{%\n\\mathcal{L}}({\\mathcal{T}}_{t}).\nroman_min start_POSTSUBSCRIPT bol", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "148", "text": "l{T}}_{t}\\sim P({\\mathcal{T}})}{%\n\\mathcal{L}}({\\mathcal{T}}_{t}).\nroman_min start_POSTSUBSCRIPT bold_italic_θ end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT caligraphic_T start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∼ italic_P ( caligraphic_T ) end_POSTSUBSCRIPT caligraphic_L ( caligraphic_T start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) .\n\n(14)\n\nIn other words, the aim is to find the optimal meta-parameters \n𝜽\n𝜽\n{\\bm{\\theta}}\nbold_italic_θ\n that minimize the expected loss across tasks, where tasks are sampled from the task distribution \nP\n⁢\n(\n𝒯\n)\n𝑃\n𝒯\nP({\\mathcal{T}})\nitalic_P ( caligraphic_T )\n.\n\nHowever, forgetting can still occur in the context of meta-learning, and it can be cla", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "149", "text": "raphic_T )\n.\n\nHowever, forgetting can still occur in the context of meta-learning, and it can be classified into two distinct research directions.\nThe first research direction focuses on Incremental Few-Shot Learning (IFSL), where the objective is to meta-learn new classes in addition to the pre-trained base classes. In this scenario, forgetting arises from the loss of information related to the pre-trained base classes. The challenge lies in retaining the knowledge of both the base classes and the newly introduced classes during the learning process.\nThe second research direction deals with Continual Meta-Learning, where the agent encounters non-stationary task distributions over time while", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "150", "text": "ontinual Meta-Learning, where the agent encounters non-stationary task distributions over time while learning new tasks. Unlike IFSL, the goal here is not to remember the specific base classes. Instead, the objective is to retain the meta-knowledge acquired from previous task distributions. We will present the details of each direction in the following.\n\nB.1 \nIncremental Few-Shot Learning\n\nIncremental few-shot learning (IFSL) \n[\n271\n, \n272\n]\n focuses on the challenge of learning new categories with limited labeled data while retaining knowledge about previously learned categories.\nIn this scenario, a standard classification network has previously undergone training to recognize a predefined ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "151", "text": "ario, a standard classification network has previously undergone training to recognize a predefined set of base classes. After that, the focus is on incorporating additional novel classes, each accompanied by only a small number of labeled examples. Subsequently, the model is tested on its classification performance, considering both the base and novel classes.\n\nExisting Works:\n Gidaris et al. \n[\n271\n]\n propose the IFSL problem and an attention-based solution to mitigate the forgetting in IFSL.\nThe Attention Attractor Network, proposed by Ren et al. \n[\n272\n]\n, is an alternative approach where the per-episode training objective during the incremental meta-learning stage is regulated using an ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "152", "text": "the per-episode training objective during the incremental meta-learning stage is regulated using an attention mechanism to attend the set of base classes. In contrast to previous approaches that extract a fixed representation for each task, XtarNet \n[\n273\n]\n emphasizes the extraction of task-adaptive representations by combining novel and base features to enhance the adaptability of the representations.\nShi et al. \n[\n274\n]\n suggest putting more effort into the base classifier pretraining stage rather than the later few-shot learning stage. As a result, they propose to seek flat local minima of the base classifier training objective function and subsequently fine-tune the model parameters wit", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "153", "text": " the base classifier training objective function and subsequently fine-tune the model parameters within that flat region when faced with new tasks.\nIn addition, C-FSCIL \n[\n111\n]\n incorporates a trainable fixed-size fully connected layer and a rewritable dynamically growing memory buffer to mitigate forgetting. This memory buffer can store a vector for each class encountered up to that point in the learning process.\n\nB.2 \nContinual Meta-Learning\n\nThe goal of continual meta-learning (CML) is to address the challenge of forgetting in non-stationary task distributions. Traditional meta-learning approaches typically focus on a single task distribution. However, CML extends this concept to handle ", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "154", "text": "proaches typically focus on a single task distribution. However, CML extends this concept to handle a sequence of task distributions, denoted as \nP\n1\n⁢\n(\n𝒯\n)\n,\nP\n2\n⁢\n(\n𝒯\n)\n,\n⋯\n,\nP\nN\n⁢\n(\n𝒯\n)\nsubscript\n𝑃\n1\n𝒯\nsubscript\n𝑃\n2\n𝒯\n⋯\nsubscript\n𝑃\n𝑁\n𝒯\nP_{1}({\\mathcal{T}}),P_{2}({\\mathcal{T}}),\\cdots,P_{N}({\\mathcal{T}})\nitalic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( caligraphic_T ) , italic_P start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( caligraphic_T ) , ⋯ , italic_P start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ( caligraphic_T )\n.\nIn CML, the objective is to develop meta-learning algorithms that can effectively adapt and generalize to new task distributions as they arise over time. These task distrib", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "155", "text": "fectively adapt and generalize to new task distributions as they arise over time. These task distributions can represent different environments, domains, or contexts. It aims to mitigate the forgetting of previously learned task distributions while efficiently adapting to new tasks.\n\nExisting Works:\n\nOnline meta-learning (OML) \n[\n275\n]\n is a framework that assumes tasks arrive sequentially and aims to improve performance on future tasks. Jerfel et al. \n[\n276\n]\n extended the Model-Agnostic Meta-Learning \n[\n204\n]\n approach and utilized Dirichlet process mixtures to group similar training tasks together. However, this method is not scalable to large-scale non-stationary distributions due to the", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "156", "text": "ogether. However, this method is not scalable to large-scale non-stationary distributions due to the requirement of independent parameters for each component.\nYap et al. \n[\n277\n]\n proposed an approach to model the posterior distribution of meta-parameters using Laplace approximation \n[\n68\n]\n. Zhang et al. \n[\n278\n]\n further extended this framework by employing a dynamical mixture model to learn the distribution of meta-parameters instead of a single distribution. Additionally, they used structural variational inference techniques to infer latent variables in the model.\nWang et al. \n[\n279\n, \n280\n, \n281\n]\n introduced a large-scale benchmark for sequential domain meta-learning. They proposed dif", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
{"id": "157", "text": "\n, \n281\n]\n introduced a large-scale benchmark for sequential domain meta-learning. They proposed different settings, including supervised learning, imbalanced domains, and semi-supervised settings, to evaluate the performance of various methods in sequential domain meta-learning.", "metadata": {"source": "web", "url": "https://arxiv.org/html/2307.09218v3", "title": "A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning"}}
